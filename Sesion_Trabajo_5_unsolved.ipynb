{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWjwtMp0_PSe"
      },
      "source": [
        "# Sesión de Trabajo 5: PREPARACIÓN DE LA BASE DE DATOS PARA ENTRENAR MODELOS PREDICTIVOS\n",
        "**Asignatura:** Ciència de Dades i Intel·ligència Artificial Aplicades a la Construcció i Estructures  \n",
        "**Institución:** ETSEIB - UPC  \n",
        "\n",
        "---\n",
        "\n",
        "## Objetivos de la sesión\n",
        "El entrenamiento de modelos de aprendizaje autónomo involucra una serie de requisitos adicionales a nuestra base de datos “limpia” que conseguimos al finalizar la Sesión de Trabajo 3. La sesión de trabajo actual se centra en llevar a cabo dichas modificaciones.\n",
        "\n",
        "\n",
        "* **S5.T1.** Selección inicial de variables de entrada y salida del modelo\n",
        "\n",
        "* **S5.T2.** Escalado/Normalización de las variables continuas\n",
        "\n",
        "* **S5.T3.** Codificación de las variables categóricas\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qejTFCk_PSp"
      },
      "source": [
        "### S5.T0. Importar la base de datos\n",
        "* Conectamos con Google Drive.\n",
        "* Cargamos el archivo `BBDD_ST3.csv`.\n",
        "* Optimizamos los tipos de datos (`float32` e `int32`) para no saturar la RAM de Colab.\n",
        "* Forzamos columnas categóricas o identificadores (como códigos postales) a string para evitar cálculos matemáticos erróneos.\n",
        "\n",
        "⏳ *Tiempo de ejecución estimado: 1-2 minutos (dependiendo de la velocidad de conexión a Drive).*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMjAGuiX_PSr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Importar librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
        "\n",
        "# Montar Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Ruta y Carga\n",
        "ruta_drive = '/content/drive/MyDrive/Sostenibilidad/BBDD_ST3.csv'\n",
        "df = pd.read_csv(ruta_drive, low_memory=False)\n",
        "\n",
        "# Optimización\n",
        "df[\"CODI_POSTAL\"] = df[\"CODI_POSTAL\"].astype('str')\n",
        "df[\"VALOR AILLAMENTS CTE\"] = df[\"VALOR AILLAMENTS CTE\"].astype('str')\n",
        "df[\"VALOR FINESTRES CTE\"] = df[\"VALOR FINESTRES CTE\"].astype('str')\n",
        "float64_cols = df.select_dtypes(include='float64').columns.tolist()\n",
        "df[float64_cols] = df[float64_cols].astype('float32')\n",
        "int64_cols = df.select_dtypes(include='int64').columns.tolist()\n",
        "df[int64_cols] = df[int64_cols].astype('int32')\n",
        "\n",
        "print(\"Base de datos limpia cargada y optimizada.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEwN0t1a_PSs"
      },
      "source": [
        "---\n",
        "\n",
        "### S5.T1. Selección inicial de variables de entrada y salida del modelo\n",
        "\n",
        "A pesar de que ahora ya disponéis de una base de datos “limpia” que os ha permito hacer correlaciones y extraer conocimiento de la sostenibilidad del parque edificado catalán, aún no habéis seleccionado las variables de entrada y la variable de salida que usaréis en vuestros modelos. Pensad que este puede ser un proceso iterativo, por lo que inicialmente se recomienda adoptar unenfoque simplificado para facilitar el entrenamiento en tiempos razonables, y en base a los resultados, ir ajustando o añadiendo parámetros.\n",
        "\n",
        "* **S5.T1.1.**  Verifica que tu dataframe no contiene NaNs\n",
        "\n",
        "* **S5.T1.2.**  Selección de la variable de salida (output)\n",
        "\n",
        "* **S5.T1.3.**  Selección de la variables de entrada (inputs)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtgrQ09D_PSu"
      },
      "source": [
        "* **S5.T1.1.** Verifica que tu dataframe no contiene NaNs\n",
        "\n",
        ">La mayoría de procesos de entrenamiento de modelos de aprendizaje autonomo no pueden operar con NaNs en la base de datos.\n",
        "\n",
        ">Para comprobar que no hay NaNs en tu dataframe, puedes usar:\n",
        "\n",
        ">>> `df.info()` o `df.isnull().sum()`\n",
        "\n",
        ">Para eliminar los NaNs, podéis referiros a la ST3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RivoKF1H_PSv"
      },
      "outputs": [],
      "source": [
        "#Insertar código aquí"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5-uU3YO_PSz"
      },
      "source": [
        "* **S5.T1.2.** Selección de la variable de salida\n",
        "\n",
        ">Se recomienda elegir la misma que en la sesión de trabajo 4: `Qualificació de consum d'energia primaria no renovable` o `Qualificacio d'emissions de CO2`). .\n",
        "\n",
        ">Elimina todos los demás outputs. Puedes usar:\n",
        "\n",
        ">>> `df= df.drop(\"Energia primària no renovable\", axis=1)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ce5YuUSF_PS3"
      },
      "outputs": [],
      "source": [
        "#Insertar código aquí"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk7a5hFL_PS2"
      },
      "source": [
        "* **S5.T1.3.** Selección de la variables de entrada (inputs)\n",
        "\n",
        ">Elimina aquellas variables de entrada categóricas que presenten un núm. de campos > 1000. En caso de duda, mejor mantener la variable.\n",
        "\n",
        ">Ejemplo:\n",
        "\n",
        ">>> `df= df.drop(\"CODI_POSTAL\", axis=1)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flnpUYcD_PS4"
      },
      "outputs": [],
      "source": [
        "#Insertar código aquí"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvPNHttX_PS6"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### S5.T2. Escalado/Normalización de las variables continuas\n",
        "\n",
        "Las variables numéricas (como metros cuadrados) deben estar en un rango similar para que el modelo no dé más peso a una variable solo por tener números más grandes.\n",
        "\n",
        "* **S5.T2.1.**  Realiza el escalado/normalización a aquellas variables continuas que consideres oportunas.\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qazU1pO_PS6"
      },
      "source": [
        "* **S5.T2.1.** Realiza el escalado/normalización a aquellas variables continuas que consideres oportunas\n",
        "\n",
        ">>**-Alternativa 1: MinMaxScaler**. Este escalador transforma los datos al rango [0, 1]. Es ideal cuando los datos están acotados y no tienen valores extremadamente altos o bajos (outliers).\n",
        "\n",
        ">>**-Alternativa 2: RobustScaler**. Este escalador utiliza la mediana y los cuartiles. Es resistente a los valores atípicos (outliers).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EJEMPLO ALTERNATIVA 1: MinMaxScaler en METRES_CADASTRE\n",
        "# 1. Preparar la figura con 2 subgráficos (1 fila, 2 columnas)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# --- GRÁFICO 1: ANTES DEL ESCALADO ---\n",
        "# Usamos histplot con kde=True\n",
        "sns.histplot(df['METRES_CADASTRE'], kde=True, ax=axes[0], color='skyblue')\n",
        "axes[0].set_title(\"Distribución Original\")\n",
        "axes[0].set_xlabel(\"Metros Cuadrados\")\n",
        "\n",
        "# --- PROCESO DE ESCALADO ---\n",
        "scaler_minmax = MinMaxScaler()\n",
        "# OJO: Hacemos el fit_transform en una copia o variable auxiliar\n",
        "# para no sobreescribir el df original antes de graficar el \"Después\"\n",
        "df['METRES_ESCALADOS'] = scaler_minmax.fit_transform(df[['METRES_CADASTRE']])\n",
        "\n",
        "# --- GRÁFICO 2: DESPUÉS DEL ESCALADO ---\n",
        "sns.histplot(df['METRES_ESCALADOS'], kde=True, ax=axes[1], color='salmon')\n",
        "axes[1].set_title(\"Distribución tras MinMaxScaler (Después)\")\n",
        "axes[1].set_xlabel(\"Valor Escalado (0 a 1)\")\n",
        "\n",
        "# Ajustar espacio entre gráficos para que no se solapen las etiquetas\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Limpieza final: borrar la columna auxiliar y modifica la original\n",
        "df['METRES_CADASTRE'] = df['METRES_ESCALADOS']\n",
        "df.drop(columns=['METRES_ESCALADOS'], inplace=True)"
      ],
      "metadata": {
        "id": "mMs2yGnyKAbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ysr5hFWe_PS7"
      },
      "outputs": [],
      "source": [
        "# EJEMPLO ALTERNATIVA 2: RobustScaler en METRES_CADASTRE\n",
        "# 1. Preparar la figura con 2 subgráficos (1 fila, 2 columnas)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# --- GRÁFICO 1: ANTES DEL ESCALADO ---\n",
        "# Usamos histplot con kde=True\n",
        "sns.histplot(df['METRES_CADASTRE'], kde=True, ax=axes[0], color='skyblue')\n",
        "axes[0].set_title(\"Distribución Original\")\n",
        "axes[0].set_xlabel(\"Metros Cuadrados\")\n",
        "\n",
        "# --- PROCESO DE ESCALADO ---\n",
        "scaler_robust = RobustScaler()\n",
        "# OJO: Hacemos el fit_transform en una copia o variable auxiliar\n",
        "# para no sobreescribir el df original antes de graficar el \"Después\"\n",
        "df['METRES_ESCALADOS'] = scaler_robust.fit_transform(df[['METRES_CADASTRE']])\n",
        "\n",
        "# --- GRÁFICO 2: DESPUÉS DEL ESCALADO ---\n",
        "sns.histplot(df['METRES_ESCALADOS'], kde=True, ax=axes[1], color='salmon')\n",
        "axes[1].set_title(\"Distribución tras RobustScaler (Después)\")\n",
        "axes[1].set_xlabel(\"Valor Escalado\")\n",
        "\n",
        "# Ajustar espacio entre gráficos para que no se solapen las etiquetas\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Limpieza final: borrar la columna auxiliar y modifica la original\n",
        "df['METRES_CADASTRE'] = df['METRES_ESCALADOS']\n",
        "df.drop(columns=['METRES_ESCALADOS'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJspAgsv_PS8"
      },
      "source": [
        ">TAREA: Normaliza/Escala las demás variables continuas con MinMaxScaler o RobustScaler.\n",
        "\n",
        ">Escribe el código a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Insertar código aquí para la normalización de la variable continua 1"
      ],
      "metadata": {
        "id": "SRJK2YxHMryZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Insertar código aquí para la normalización de la variable continua 2 ..."
      ],
      "metadata": {
        "id": "ormFxdgOMyqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9yl9HtO_PS8"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### S5.T3. Codificación de las variables categóricas\n",
        "\n",
        "Los modelos de aprendizaje autónomo no pueden trabajar directamente con datos categóricos, necesitan datos numéricos.Para ello, antes de entrenar o evaluar cualquier modelo es esencial que codifiquéis las variables categóricas de vuestra basededatos. Se distinguen principalmente tres enfoques distintos para llevar a cabo esta tarea en función de la naturaleza de la variable categórica.\n",
        "\n",
        "* **S5.T3.1. Variables categóricas binarias:**  Únicamente 2 campos posibles (Sí/No, ...).\n",
        "\n",
        "* **S5.T3.2. Variables categóricas ordinales:**  Tienen un orden o jerarquía.   \n",
        "\n",
        "* **S5.T3.3. Variables categóricas nominales:**  Sin orden jerárquico.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2xzGz6u_PS9"
      },
      "source": [
        "---\n",
        "\n",
        "TAREA INICIAL: Haz doble-click en esta celda y completa las listas a continuación con los nombres de las columnas de tu dataframe según el tipo de variable categórica:\n",
        "\n",
        "* **Variables Binarias:** `[\"VEHICLE ELECTRIC\", ...]`\n",
        "* **Variables Ordinales:** `[\"Qualificació...\", ...]`\n",
        "* **Variables Nominales:** `[\"Eina de certificacio\", ...]`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjSgCB-l_PS9"
      },
      "source": [
        "* **S5.T3.1.** Variables categóricas binarias\n",
        "\n",
        ">Únicamente tienen dos valores posibles. En este caso, simplemente hay que reemplazar los valores originales nominales por valores numéricos (0/1). Recordad que solo deben modificarse aquellas que no estén en formato numérico (Si/No).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zaYasSX_PS-"
      },
      "outputs": [],
      "source": [
        "# Ejemplo Variable Binaria: \"VEHICLE ELECTRIC\"\n",
        "\n",
        "# Mostrar el estado inicial para la clase\n",
        "print(\"--- ESTADO INICIAL (Primeros 5 registros) ---\")\n",
        "print(df[[\"VEHICLE ELECTRIC\"]].head())\n",
        "\n",
        "# 3. Aplicar la codificación numérica (Sustitución directa)\n",
        "# Asignamos 0 a la ausencia (NO) y 1 a la presencia (SI)\n",
        "mapeo_binario = {'NO': 0, 'SI': 1}\n",
        "df[\"VEHICLE ELECTRIC\"] = df[\"VEHICLE ELECTRIC\"].replace(mapeo_binario)\n",
        "\n",
        "# 4. Mostrar el resultado final\n",
        "print(\"\\n--- ESTADO TRAS LA CODIFICACIÓN ---\")\n",
        "print(df[[\"VEHICLE ELECTRIC\"]].head())\n",
        "\n",
        "# 5. Verificación de tipo de dato\n",
        "print(f\"\\nNuevo tipo de dato de la columna: {df['VEHICLE ELECTRIC'].dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmpmsBFY_PS-"
      },
      "source": [
        ">TAREA: Completa la codificación de las demás variables binarias.\n",
        "\n",
        ">Escribe el código a continuación (puedes ponerlo todo en una única celda, como prefieras):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Insertar código aquí para la codificación de las demás variables binarias."
      ],
      "metadata": {
        "id": "a8wqg1ZVRec4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUWIcpiN_PS_"
      },
      "source": [
        "* **S5.T3.2.** Variables categóricas ordinales\n",
        "\n",
        ">Tienen un orden lógico o jerarquía (ej. Calificaciones energéticas de A a G).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25cDhq_A_PS_"
      },
      "outputs": [],
      "source": [
        "# Ejemplo Variable Ordinal: \"Qualificació de consum d'energia primaria no renovable\"\n",
        "\n",
        "# 1. Mostrar los valores únicos antes de la transformación\n",
        "# Es importante que vean que las categorías tienen un orden lógico (A-G)\n",
        "print(\"--- CATEGORÍAS ORIGINALES ---\")\n",
        "print(df[\"Qualificació de consum d'energia primaria no renovable\"].unique())\n",
        "\n",
        "# 2. Definir el diccionario de mapeo jerárquico\n",
        "# Asignamos valores numéricos que respeten el orden de eficiencia\n",
        "# G (peor) = 0, A (mejor) = 6\n",
        "ord_energetico = {\n",
        "    'G': 0,\n",
        "    'F': 1,\n",
        "    'E': 2,\n",
        "    'D': 3,\n",
        "    'C': 4,\n",
        "    'B': 5,\n",
        "    'A': 6\n",
        "}\n",
        "\n",
        "# 3. Aplicar la transformación mediante .map()\n",
        "# Usamos .map() porque es más eficiente para sustituciones completas de diccionarios\n",
        "df[\"Qualificació de consum d'energia primaria no renovable\"] = \\\n",
        "    df[\"Qualificació de consum d'energia primaria no renovable\"].map(ord_energetico)\n",
        "\n",
        "# 4. Mostrar el resultado final y la distribución\n",
        "print(\"\\n--- RESULTADO TRAS EL MAPEO ORDINAL ---\")\n",
        "print(df[\"Qualificació de consum d'energia primaria no renovable\"].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFEapEjN_PTC"
      },
      "source": [
        ">TAREA: Completa la codificación de las demás variables ordinales.\n",
        "\n",
        ">Escribe el código a continuación (puedes ponerlo todo en una única celda, como prefieras):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Insertar código aquí para la codificación de las demás variables ordinales."
      ],
      "metadata": {
        "id": "ZHeMlvolSuGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJTMGszy_PTC"
      },
      "source": [
        "* **S5.T3.2.** Variables categóricas nominales\n",
        "\n",
        ">Aquí no hay un orden (la herramienta \"CE3X\" no es \"mayor\" que \"HULC\"), por lo que no podemos usar números seguidos como 0, 1, 2. Si lo hiciéramos, el modelo pensaría erróneamente que existe una jerarquía.\n",
        "\n",
        "Utilizamos One-Hot Encoding (get_dummies), que expande la columna en varias columnas de \"presencia/ausencia\" (1 o 0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLxxIO0-_PTD"
      },
      "outputs": [],
      "source": [
        "# Ejemplo Variable Ordinal: \"Eina de certificacio\"\n",
        "\n",
        "# 1. Mostrar estado inicial\n",
        "print(\"--- CATEGORÍAS NOMINALES DETECTADAS ---\")\n",
        "categorias = df[\"Eina de certificacio\"].unique()\n",
        "print(categorias)\n",
        "\n",
        "# 2. Aplicar One-Hot Encoding (pd.get_dummies)\n",
        "# Esto eliminará la columna original y creará una por cada categoría\n",
        "df = pd.get_dummies(df, columns=[\"Eina de certificacio\"])\n",
        "\n",
        "# 3. Mostrar el resultado de las nuevas columnas creadas\n",
        "# Buscamos las columnas que empiezan por el nombre original para ver el cambio\n",
        "nuevas_cols = [col for col in df.columns if \"Eina de certificacio\" in col]\n",
        "\n",
        "print(\"\\n--- NUEVAS COLUMNAS CREADAS (Dummies) ---\")\n",
        "print(df[nuevas_cols].head())\n",
        "\n",
        "# 4. Verificación del tamaño del DataFrame\n",
        "# Al usar dummies, el número de columnas (ancho del df) siempre aumenta\n",
        "print(f\"\\nNúmero total de columnas ahora: {df.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZTir07I_PTE"
      },
      "source": [
        ">TAREA: Completa la codificación de las demás variables nominales.\n",
        "\n",
        ">Escribe el código a continuación (puedes ponerlo todo en una única celda, como prefieras):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Insertar código aquí para la codificación de las demás variables nominales."
      ],
      "metadata": {
        "id": "TrzinimPTixG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0XDhMs8_PTE"
      },
      "source": [
        "Eliminar observaciones duplicadas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_antes_dupl = len(df)\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Registros duplicados eliminados: {n_antes_dupl - len(df)}\")"
      ],
      "metadata": {
        "id": "yVWVTc0-Tv62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar BBDD limpia codificada"
      ],
      "metadata": {
        "id": "jgdE9Y3mTypN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fgg6aDwp_PTR"
      },
      "outputs": [],
      "source": [
        "# Usamos la misma carpeta donde cargamos la BBDD_ST3\n",
        "ruta_salida = '/content/drive/MyDrive/Sostenibilidad/BBDD_ST5.csv'\n",
        "df.to_csv(ruta_salida, index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}