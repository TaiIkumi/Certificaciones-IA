{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZcUBKs6UO2-"
      },
      "source": [
        "# Sesión de Trabajo 5: ENTRENAMIENTO DE MODELOS DE INTELIGENCIA ARTIFICIAL (ANN)\n",
        "\n",
        "**Asignatura:** Ciència de Dades i Intel·ligència Artificial Aplicades a la Construcció i Estructures  \n",
        "**Institución:** ETSEIB - UPC  \n",
        "\n",
        "---\n",
        "\n",
        "## Objetivos de la sesión\n",
        "La S6 comprende tanto el desarrollo de modelos predictivos de aprendizaje autónomo como la evaluación y extracción de conocimiento a partir de los mismos. Esta sesión se divide en 2 partes:\n",
        "\n",
        "-La primera parte tiene como objetivo entrenar y evaluar el rendimiento de un modelo de clasificación multiclase para la predicción de la calificación elegida que comprenda lo mejor posible la relación entre los datos de entrada y el resultado de la certificación energética obtenida.Modelos elegidos:“NeuralNetwork”\n",
        "\n",
        "-Una vez obtenido el mejor modelo posible, el objetivo de la segunda parte de la S6 es extraer conocimiento de la sostenibilidad del parque edificado catalán a partir del modelo entrenado.\n",
        "\n",
        "\n",
        "* **S6.T0.** Separación de las variables de entrada (X) / salida (Y) y el set de entrenamiento/validación de la BBDD\n",
        "\n",
        "* **S6.T1.** Configuración y entrenamiento de un clasificador basado en ANN\n",
        "\n",
        "* **S6.T2.** Evaluación del rendimiento del modelo\n",
        "\n",
        "* **S6.T3.** Interpretación del modelo\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyZr4L1TUO3T"
      },
      "source": [
        "### S6.T0. Importar la base de datos y preparación de los datasets\n",
        "* Conectamos con Google Drive.\n",
        "* Cargamos el archivo `BBDD_ST5.csv`.\n",
        "* Optimizamos los tipos de datos (`float32` e `int32`) para no saturar la RAM de Colab.\n",
        "* Creación Dataset input/outputs\n",
        "* División Train/Test (80 % entrenamiento, 20 % validación)\n",
        "\n",
        "⏳ *Tiempo de ejecución estimado: 1-2 minutos (dependiendo de la velocidad de conexión a Drive).*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DJNnLJVUO3X"
      },
      "outputs": [],
      "source": [
        "# Importar librerías\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import shap\n",
        "\n",
        "# Configuración\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "pd.set_option('future.no_silent_downcasting', True)\n",
        "\n",
        "# Montar Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Ruta y Carga\n",
        "ruta_drive = '/content/drive/MyDrive/Sostenibilidad/BBDD_ST5.csv'\n",
        "df = pd.read_csv(ruta_drive, low_memory=False)\n",
        "\n",
        "# Optimización\n",
        "\n",
        "float64_cols = df.select_dtypes(include='float64').columns.tolist()\n",
        "df[float64_cols] = df[float64_cols].astype('float32')\n",
        "int64_cols = df.select_dtypes(include='int64').columns.tolist()\n",
        "df[int64_cols] = df[int64_cols].astype('int32')\n",
        "\n",
        "# División de datos\n",
        "target = \"Qualificació de consum d'energia primaria no renovable\"\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    df.drop(target, axis=1), #Inputs\n",
        "    df[target], #Output\n",
        "    test_size=0.2, #Tamaño del set de validación (20%)\n",
        "    random_state=1 # Semilla para controlar la aleatoriedad. No tocar\n",
        ")\n",
        "\n",
        "print(f\"Base de datos cargada. Entrenamiento: {x_train.shape[0]} | Test: {x_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjk1ZG7RUO3e"
      },
      "source": [
        "---\n",
        "\n",
        "### S6.T1. Configuración y entrenamiento de la Red Neuronal (ANN)\n",
        "\n",
        "Entrena un modelo basado en “Neural Network” para predecir la calificación energética de un edificio (el output serán la calificación energética obtenida).\n",
        "\n",
        "Podéis evaluar la influencia de los siguientes parámetros en la eficiencia del modelo:\n",
        "\n",
        "* **Capas ocultas y neuronas por capa:** Define la profundidad del \"cerebro\". Ejemplo: (10, 20) son dos capas con 10 y 20 neuronas respectivamente.\n",
        "\n",
        "* **Iteraciones**: Es el número de veces que el modelo revisa los datos (épocas). Si es muy bajo, no aprende; si es muy alto, tarda demasiado.\n",
        "\n",
        "* **Tasa de aprendizaje (learning rate)**: Controla qué tan rápido cambia el modelo en respuesta al error.\n",
        "\n",
        ">>-Muy alta: El modelo aprende rápido pero puede volverse inestable.\n",
        "\n",
        ">>-Muy baja: El aprendizaje es muy lento y puede quedar atrapado en errores locales.\n",
        "\n",
        "* **Pesos de clase**: Como hay pocos edificios con calificación 'A' o 'B', usamos pesos_clases para que la IA les preste más atención y no los ignore.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcF3p6-EUO3k"
      },
      "outputs": [],
      "source": [
        "# --- PASO 1: Define los hiperparámetros (¡Experimenta aquí!) para mejorar el Accuracy ---\n",
        "capas_ocultas = (10, 20)\n",
        "iteraciones = 20\n",
        "tasa_aprendizaje = 0.0005\n",
        "pesos_clases = {0: 1.63, 1: 2.91, 2: 0.7, 3: 4.05, 4: 10.3, 5: 44.3, 6: 142.2}\n",
        "\n",
        "# --- PASO 2: Crear el modelo ---\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=capas_ocultas,\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=iteraciones,\n",
        "    learning_rate_init=tasa_aprendizaje,\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.1,\n",
        "    random_state=1234,\n",
        "    verbose=True # Para ver la evolución del error en cada paso\n",
        ")\n",
        "\n",
        "# --- PASO 3: Entrenar ---\n",
        "print(\"Entrenando... Observa cómo disminuye el 'loss' (error) en cada iteración.\")\n",
        "mlp.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8geLiuF2UO3o"
      },
      "source": [
        "---\n",
        "\n",
        "### S6.T2. Evaluación del rendimiento del modelo\n",
        "\n",
        "Finalizado el entrenamiento, es imperativo realizar un diagnóstico del comportamiento del modelo. No se debe considerar únicamente el valor de precisión final, sino también la dinámica del aprendizaje:\n",
        "\n",
        "* **Análisis de convergencia (Loss y Accuracy):**\n",
        "\n",
        ">* Función de Pérdida (Loss): Representa el error del modelo. Se busca una disminución monótona y suave. Una curva errática puede indicar una tasa de aprendizaje demasiado elevada.\n",
        "\n",
        ">* Precisión en Validación (Accuracy): Monitorizamos cómo mejora el acierto en datos no utilizados para el entrenamiento. Si la pérdida disminuye pero la precisión en validación se estanca o empeora, el modelo podría estar incurriendo en sobreajuste (overfitting).\n",
        "\n",
        "* **Matriz de Confusión Normalizada**: Este análisis permite identificar errores sistemáticos entre categorías adyacentes (por ejemplo, confusión entre las calificaciones B y C).\n",
        "\n",
        ">* Los valores de la diagonal principal representan el Recuperación (Recall) o sensibilidad por clase: la probabilidad de que el modelo clasifique correctamente un inmueble dada su categoría real.\n",
        ">* Un valor de 0.85 en la diagonal de la \"Clase E\" indica que el modelo identifica correctamente el 85% de los edificios de esa categoría.\n",
        ">* Los valores fuera de la diagonal indican errores sistemáticos. Por ejemplo, un 0.10 en la intersección de Real: B y Predicho: C significa que el 10% de los edificios tipo B son erróneamente clasificados como C.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. EVALUACIÓN DE LA DINÁMICA DE APRENDIZAJE ---\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Análisis de la Función de Pérdida (Convergencia)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(mlp.loss_curve_, color='#e74c3c', lw=2, label='Training Loss')\n",
        "plt.fill_between(range(len(mlp.loss_curve_)), mlp.loss_curve_, color='#e74c3c', alpha=0.1)\n",
        "plt.title('Curva de Convergencia: Función de Pérdida', fontsize=13)\n",
        "plt.xlabel('Iteraciones (Épocas)')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True, ls='--', alpha=0.5)\n",
        "plt.legend()\n",
        "\n",
        "# Análisis de la Evolución de la Precisión\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(mlp.validation_scores_, color='#2ecc71', lw=2, label='Validation Accuracy')\n",
        "plt.title('Evolución de la Precisión durante el Entrenamiento', fontsize=13)\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True, ls='--', alpha=0.5)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 2. EXAMEN FINAL DEL MODELO (SET DE TEST) ---\n",
        "y_pred = mlp.predict(x_test)\n",
        "\n",
        "print(\"\\n\" + \"=\"*65)\n",
        "print(\"             INFORME TÉCNICO DE MÉTRICAS DE CLASIFICACIÓN\")\n",
        "print(\"=\"*65)\n",
        "# El reporte permite evaluar el rendimiento específico para cada letra energética\n",
        "print(classification_report(y_test, y_pred, target_names=[\"G\", \"F\", \"E\", \"D\", \"C\", \"B\", \"A\"], zero_division=0))\n",
        "\n",
        "# Matriz de Confusión Normalizada (Probabilidad de acierto por categoría)\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_norm = confusion_matrix(y_test, y_pred, normalize='true')\n",
        "sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='YlGnBu',\n",
        "            xticklabels=[\"G\", \"F\", \"E\", \"D\", \"C\", \"B\", \"A\"],\n",
        "            yticklabels=[\"G\", \"F\", \"E\", \"D\", \"C\", \"B\", \"A\"])\n",
        "plt.title('Análisis de Errores: Matriz de Confusión Normalizada', fontsize=14)\n",
        "plt.xlabel('Predicción del Modelo')\n",
        "plt.ylabel('Categoría Real')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hb9G6tSkk2tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### S6.T3. Análisis de interpretabilidad mediante SHAP\n",
        "\n",
        "Las redes neuronales son consideradas a menudo modelos de \"caja negra\" (black box) debido a la dificultad de trazar cómo los pesos y las funciones de activación transforman los inputs en una predicción. Para resolver esto, utilizaremos los valores SHAP (Shapley Additive Explanations).\n",
        "\n",
        "¿Cómo interpretar el gráfico de SHAP (Summary Plot)?\n",
        "\n",
        "* Distribución de importancia: Las variables aparecen ordenadas de arriba a abajo según su influencia global en el modelo. La variable superior es la que más \"pesa\" en la decisión de la red.\n",
        "\n",
        "* Impacto (Eje X): Los puntos a la derecha del centro (valor 0) indican que esa variable aumenta la probabilidad de que el edificio pertenezca a la clase analizada (ej. Clase A). Los puntos a la izquierda indican que la disminuyen.\n",
        "\n",
        "* Valor de la variable (Color): * El rojo representa un valor alto de la característica (ej. muchos metros cuadrados).\n",
        "\n",
        "* El azul representa un valor bajo (ej. pocos metros cuadrados).\n",
        "\n",
        "Validación del conocimiento experto: El estudiante debe analizar si la IA ha aprendido relaciones lógicas. Por ejemplo: ¿Es coherente que un valor bajo en biomasa (azul) desplace la predicción hacia la derecha (Clase A)? Si la respuesta es afirmativa, el modelo es físicamente consistente.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "RP__rc4aoVab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selección de muestras representativas para reducir el coste computacional\n",
        "x_test_resumido = shap.sample(x_test, 50)\n",
        "x_train_resumido = shap.sample(x_train, 100)\n",
        "\n",
        "print(\"Ejecutando el cálculo de valores SHAP para la interpretación del modelo...\")\n",
        "explainer = shap.KernelExplainer(mlp.predict_proba, x_train_resumido)\n",
        "shap_values = explainer.shap_values(x_test_resumido)\n",
        "\n",
        "# Visualización de la importancia de variables para la Calificación 'A' (Índice 6)\n",
        "shap_values_array = np.array(shap_values).transpose(2, 0, 1)\n",
        "print(\"\\nDiagrama de impacto de variables para la Clase A:\")\n",
        "shap.summary_plot(shap_values_array[6], x_test_resumido, plot_type=\"dot\")\n",
        "\n",
        "# Nota: Evalúa todas las clases cambiando el índice. Por ejemplo, para la Clase G, cambie el índice a [0] según la codificación realizada en la ST5."
      ],
      "metadata": {
        "id": "5bIdP052ohm0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}