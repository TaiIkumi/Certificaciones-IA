{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\nImportar librerias<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import seaborn as sns\n", "import matplotlib\n", "import matplotlib.pyplot as plt\n", "matplotlib.use('TkAgg')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nS3.T0. Importar la base de datos a PyCharm<br>\n", "\u00ef\u0192\u02dc Guarda la base de datos en un dataframe llamado \"df\"<br>\n", "\u00ef\u0192\u02dc El dtype de las columnas indicadas a continuaci\u00c3\u00b3n las convertimos de float64/int64 a float32/int32 para reducir memoria<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(r'E:\\Laptop\\BBDD_ST2.csv')  # Definir ruta de la BBDD\n", "float64_cols = df.select_dtypes(include='float64').columns.tolist()  # Seleccionar columnas de tipo float64\n", "df[float64_cols] = df[float64_cols].astype('float32')  # Convertir columnas de tipo float64 a float32\n", "int64_cols = df.select_dtypes(include='int64').columns.tolist()  # Seleccionar columnas de tipo int64\n", "df[int64_cols] = df[int64_cols].astype('int32')  # Convertir columnas de tipo int64 a int32"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n S3.T1. Tratamiento de datos NO RELEVANTES<br>\n", "\u00ef\u0192\u02dc Eliminar columnas no informativas debido a su alta repetitividad de sus observaciones<br>\n", "\u00ef\u0192\u02dc Eliminar columnas no informativas debido a su nula relaci\u00c3\u00b3n con el fen\u00c3\u00b3meno de estudio<br>\n", "\u00ef\u0192\u02dc Eliminar observaciones duplicadas. Esto se deber\u00c3\u00ada hacer al final de la limpieza de la BBDD<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["TODO: Eliminar columnas no informativas debido a su alta repetitividad de sus observaciones"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO: Identificar columnas no informativas por repetici\u00c3\u00b3n de valores o NaNs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['SOLAR TERMICA'].value_counts(dropna=False) * 100 / len(df.index)  # 100 % NO\n", "df['INFORME_INS_TECNICA_EDIFICI'].value_counts(dropna=False) * 100 / len(df.index)  # 99.83 % NaN"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO: Eliminar columnas no informativas por repetici\u00c3\u00b3n de valores o NaNs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df.drop('SOLAR TERMICA', axis=1)  # 100 % NO\n", "df = df.drop('INFORME_INS_TECNICA_EDIFICI', axis=1)  # 99.83 % NaN"]}, {"cell_type": "markdown", "metadata": {}, "source": ["PRECAUCI\u00c3\u201cN: Variables con pocos datos pero valiosos. Antes de eliminar una variable, mejor analizar su distribuci\u00c3\u00b3n<br>\n", "con atenci\u00c3\u00b3n y asegurar que no aporta informaci\u00c3\u00b3n relevante para el fen\u00c3\u00b3meno de estudio"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ind_typos = df[df['VEHICLE ELECTRIC'] == 'SI'].index  # Identificar \u00c3\u00adndices de observaciones con VEHICLE ELECTRIC = SI\n", "a = df.loc[ind_typos,\"Qualificaci\u00c3\u00b3 de consum d'energia primaria no renovable\"]  # Extraer valores del output con VEHICLE ELECTRIC = SI"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()  # Crear una nueva ventana para la gr\u00c3\u00a1fica\n", "a.value_counts(dropna=False).plot(kind=\"pie\")  # Visualizar distribuci\u00c3\u00b3n de OUTPUT donde VEHICLE ELECTRIC = SI"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()  # Crear una nueva ventana para la segunda gr\u00c3\u00a1fica\n", "df[\"Qualificaci\u00c3\u00b3 de consum d'energia primaria no renovable\"].value_counts(dropna=False).plot(kind=\"pie\")  # Visualizar distribuci\u00c3\u00b3n de OUTPUT en todo el dataframe"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()  # Mostrar ambas gr\u00c3\u00a1ficasualizar distribuci\u00c3\u00b3n de OUTPUT global"]}, {"cell_type": "markdown", "metadata": {}, "source": ["TAREA: Identifica y elimina las columnas no informativas por repetici\u00c3\u00b3n de valores o NaNs (APROX. 30 VARIABLES)<br>\n", "Continuar la lista... Justificando la eliminaci\u00c3\u00b3n de cada columna en un comentario adjunto."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df.drop('ANY_CONSTRUCCIO', axis=1)  # 984691 NaN\n", "df = df.drop('Tipus Tramit', axis=1)  # 99 % la mateixa categoria\n", "df = df.drop('SOLAR TERMICA', axis=1)  # 100 % NO\n", "df = df.drop('INFORME_INS_TECNICA_EDIFICI', axis=1)  # 99.83 % NaN"]}, {"cell_type": "markdown", "metadata": {}, "source": ["TODO: Eliminar columnas no informativas debido a su nula relaci\u00c3\u00b3n con el fen\u00c3\u00b3meno de estudio"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO: Eliminar columnas no informativas para el fen\u00c3\u00b3meno de estudio"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df.drop('NUM_CAS', axis=1)  # Elimina de df la columna NUM_CAS por ser identificador de la observaci\u00c3\u00b3n\n", "df = df.drop('ADRE\u00c3\u2021A', axis=1)  # Elimina de df la columna ADRE\u00c3\u2021A por ser no informativa para el fen\u00c3\u00b3meno de estudio"]}, {"cell_type": "markdown", "metadata": {}, "source": ["TAREA: Completa la eliminaci\u00c3\u00b3n de columnas no informativas para el fen\u00c3\u00b3meno de estudio (APROX. 4 VARIABLES)<br>\n", "Continuar la lista... Justificando la eliminaci\u00c3\u00b3n de cada columna en un comentario adjunto."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df.drop('NUM_CAS', axis=1)  # NUM_CAS es una variable identificativa, sin informaci\u00c3\u00b3n relevante"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n S3.T2. Tratamiento de datos INCONSISTENTES<br>\n", "\u00ef\u0192\u02dc Uniformizar uso de las may\u00c3\u00basculas/min\u00c3\u00basculas y corregir errores de escritura en variables categ\u00c3\u00b3ricas<br>\n", "\u00ef\u0192\u02dc Errores de formato en direcciones, n\u00c3\u00bameros, \u00e2\u20ac\u00a6<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["TODO: Uniformizar uso de las may\u00c3\u00basculas/min\u00c3\u00basculas y corregir errores de escritura en variables categ\u00c3\u00b3ricas"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO: Uniformizar may\u00c3\u00basculas/min\u00c3\u00basculas"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['NOM_PROVINCIA'].value_counts(dropna=False)  # Distribuci\u00c3\u00b3n de valores de NOM_PROVINCIA\n", "df['NOM_PROVINCIA'] = df['NOM_PROVINCIA'].str.lower()  # Convertir a min\u00c3\u00basculas"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO: Corregir errores de escritura"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['US_EDIFICI'].value_counts(dropna=False)  # Distribuci\u00c3\u00b3n de valores de US_EDIFICI\n", "ind_typos = df[df['US_EDIFICI'] == 'Terciario'].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = Terciario\n", "df.loc[ind_typos, 'US_EDIFICI'] = 'Terciari'  # Corregir US_EDIFICI = Terciario por Terciari"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO: Eliminar observaciones con ciertas subcategor\u00c3\u00adas err\u00c3\u00b3neas, pero que no tenemos criterio para corregir"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['US_EDIFICI'].value_counts(dropna=False)  # Distribuci\u00c3\u00b3n de valores de US_EDIFICI\n", "ind_typos = df[df[\"US_EDIFICI\"] == \"Habitatge\"].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = Habitatge\n", "df.drop(ind_typos, axis=0)  # Eliminar observaciones con US_EDIFICI = Habitatge"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO: Variable que el esfuerzo para corregir estos aspectos puede ser NO ASUMIBLE para el beneficio que aporta"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['POBLACIO'].value_counts(dropna=False)  # Distribuci\u00c3\u00b3n de valores de POBLACIO. Vemos hay que muchisimos valores err\u00c3\u00b3neos"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO DE TRATAMIENTO COMPLETO DE UNA VARIABLE: Limpieza de NOM_PROVINCIA"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['NOM_PROVINCIA'].value_counts(dropna=False)  # Distribuci\u00c3\u00b3n de valores de NOM_PROVINCIA\n", "df['NOM_PROVINCIA'] = df['NOM_PROVINCIA'].str.lower()  # Convertir a min\u00c3\u00basculas\n", "ind_typos = df[df['NOM_PROVINCIA'] == '0'].index  # Identificar \u00c3\u00adndices de observaciones con NOM_PROVINCIA = 0\n", "df = df.drop(ind_typos, axis=0)  # Eliminar observaciones con NOM_PROVINCIA = 0. No podemos corregir pues no tenemos criterio.\n", "col_name = \"NOM_PROVINCIA\"  # Nombre de la variable a tratar\n", "first_col = df.pop(col_name)  # Extraer la variable a tratar de df\n", "df.insert(0, col_name, first_col)  # Insertar la variable a tratar en la primera posici\u00c3\u00b3n de df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO DE TRATAMIENTO COMPLETO DE UNA VARIABLE: Limpieza de US_EDIFICI"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['US_EDIFICI'].value_counts(dropna=False)  # Distribuci\u00c3\u00b3n de valores de US_EDIFICI\n", "df['US_EDIFICI'] = df['US_EDIFICI'].str.lower()  # Convertir a min\u00c3\u00basculas\n", "ind_typos = df[df['US_EDIFICI'] == 'terciario'].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = terciario\n", "df.loc[ind_typos, 'US_EDIFICI'] = 'terciari'  # Corregir US_EDIFICI = terciario por terciari\n", "ind_typos = df[df['US_EDIFICI'] == 'vivienda individual en bloque de viviendas'].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = vivienda individual en bloque de viviendas\n", "df.loc[ind_typos, 'US_EDIFICI'] = \"habitatge individual en bloc d'habitatges\"  # Corregir US_EDIFICI = vivienda individual en bloque de viviendas por habitatge individual en bloc d'habitatges\n", "ind_typos = df[df['US_EDIFICI'] == 'vivienda unifamiliar'].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = vivienda unifamiliar\n", "df.loc[ind_typos, 'US_EDIFICI'] = \"habitatge unifamiliar\"  # Corregir US_EDIFICI = vivienda unifamiliar por habitatge unifamiliar\n", "ind_typos = df[df['US_EDIFICI'] == \"bloc d'habitatges\"].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = bloc d'habitatges\n", "df.loc[ind_typos, 'US_EDIFICI'] = \"bloc d'habitatges plurifamiliar\"  # Corregir US_EDIFICI = bloc d'habitatges por bloc d'habitatges plurifamiliar\n", "ind_typos = df[df['US_EDIFICI'] == \"bloque de viviendas\"].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = bloque de viviendas\n", "df.loc[ind_typos, 'US_EDIFICI'] = \"bloc d'habitatges plurifamiliar\"  # Corregir US_EDIFICI = bloque de viviendas por bloc d'habitatges plurifamiliar\n", "ind_typos = df[df['US_EDIFICI'] == \"habitatge plurifamiliar\"].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = habitatge plurifamiliar\n", "df.loc[ind_typos, 'US_EDIFICI'] = \"bloc d'habitatges plurifamiliar\"  # Corregir US_EDIFICI = habitatge plurifamiliar por bloc d'habitatges plurifamiliar\n", "ind_typos = df[df['US_EDIFICI'] == \"habitatge unifamiliar a\u00c3\u00afllat\"].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = habitatge unifamiliar a\u00c3\u00afllat\n", "df.loc[ind_typos, 'US_EDIFICI'] = \"habitatge unifamiliar\"  # Corregir US_EDIFICI = habitatge unifamiliar a\u00c3\u00afllat por habitatge unifamiliar\n", "ind_typos = df[df['US_EDIFICI'] == \"habitatge unifamiliar adossat\"].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = habitatge unifamiliar adossat\n", "df.loc[ind_typos, 'US_EDIFICI'] = \"habitatge unifamiliar\"  # Corregir US_EDIFICI = habitatge unifamiliar adossat por habitatge unifamiliar\n", "ind_typos = df[df['US_EDIFICI'] == \"bloque de viviendas plurifamiliar\"].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = bloque de viviendas plurifamiliar\n", "df.loc[ind_typos, 'US_EDIFICI'] = \"bloc d'habitatges plurifamiliar\"  # Corregir US_EDIFICI = bloque de viviendas plurifamiliar por bloc d'habitatges plurifamiliar\n", "ind_typos = df[df['US_EDIFICI'] == \"terciari: locals, oficines...\"].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = terciari: locals, oficines...\n", "df.loc[ind_typos, 'US_EDIFICI'] = \"terciari\"  # Corregir US_EDIFICI = terciari: locals, oficines... por terciari"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["value_counts = df['US_EDIFICI'].value_counts(dropna=False)  # Distribuci\u00c3\u00b3n de valores de US_EDIFICI\n", "to_remove = value_counts[value_counts <= 400].index  # Identificar \u00c3\u00adndices de US_EDIFICI con menos de 400 observaciones\n", "df = df[~df.US_EDIFICI.isin(to_remove)]  # Eliminar observaciones con US_EDIFICI con menos de 400 observaciones"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["col_name = \"US_EDIFICI\"  # Nombre de la variable a tratar\n", "first_col = df.pop(col_name)  # Extraer la variable a tratar de df\n", "df.insert(0, col_name, first_col)  # Insertar la variable a tratar en la primera posici\u00c3\u00b3n de df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["TAREA: Uniformiza el uso de may\u00c3\u00basculas/min\u00c3\u00basculas y corrige los errores de escritura en variables categ\u00c3\u00b3ricas.<br>\n", "Para facilitar la tarea, se os empieza la limpieza de las variables."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # Limpieza COMARCA. Continuar la lista..."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['COMARCA'].value_counts(dropna=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ind_typos = df[df['COMARCA'] == \"Barcelon\u00c3\u00a9s\"].index\n", "df.loc[ind_typos, 'COMARCA'] = \"Barcelon\u00c3\u00a8s\"\n", "ind_typos = df[df['COMARCA'] == \"Barcelon\u00c2\u00bfs\"].index\n", "df.loc[ind_typos, 'COMARCA'] = \"Barcelon\u00c3\u00a8s\"\n", "ind_typos = df[df['COMARCA'] == \"Vall\u00c3\u00bds Oriental\"].index\n", "df.loc[ind_typos, 'COMARCA'] = \"Vall\u00c3\u00a8s Oriental\"\n\n", "    # Limpieza de Eines de certificacio. Continuar la lista..."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["index_null = df[df[\"Eina de certificacio\"].isnull()].index\n", "df = df.drop(index_null, axis=0)\n", "ind_typos = df[df['Eina de certificacio'] == \"CE3x\"].index\n", "df.loc[ind_typos, 'Eina de certificacio'] = \"CE3X\"\n", "ind_typos = df[df['Eina de certificacio'] == \"CALENER VYP\"].index\n", "df.loc[ind_typos, 'Eina de certificacio'] = \"CALENER\"\n\n", "    # Limpieza Motiu de la certificacio. Continuar la lista..."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['Motiu de la certificacio'] = df['Motiu de la certificacio'].str.lower()\n", "ind_typos = df[df['Motiu de la certificacio'] == 'alquiler'].index\n", "df.loc[ind_typos, 'Motiu de la certificacio'] = 'lloguer'\n", "ind_typos = df[df['Motiu de la certificacio'] == 'compravenda'].index\n", "df.loc[ind_typos, 'Motiu de la certificacio'] = 'compra o venda'\n\n", "    # Limpieza Normativa construcci\u00c3\u00b3. Continuar la lista..."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['Normativa construcci\u00c3\u00b3'] = df['Normativa construcci\u00c3\u00b3'].str.lower()\n", "ind_typos = df[df['Normativa construcci\u00c3\u00b3'] == 'antes de 1979'].index\n", "df.loc[ind_typos, 'Normativa construcci\u00c3\u00b3'] = 'abans de 1979'\n\n", "    # Limpieza TITULACIO_TECNIC. Continuar la lista..."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['TITULACIO_TECNIC'] = df['TITULACIO_TECNIC'].str.lower()\n", "ind_typos = df[df['TITULACIO_TECNIC'] == 'arquitecto t\u00c3\u00a9cnico'].index\n", "df.loc[ind_typos, 'TITULACIO_TECNIC'] = 'arquitecte t\u00c3\u00a8cnic'\n\n", "    # Limpieza PIS. Continuar la lista...(campos sugeridos: \"SOT\", \"BX\", \"EN\", \"PR\", \"1\", \"2\", \"3\", \"4\", \"5-9\", \">10\", \"AT\", \"SA\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ind_typos = df[df['US_EDIFICI'] == \"bloc d'habitatges plurifamiliar\"].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = bloc d'habitatges plurifamiliar\n", "df.loc[ind_typos, 'PIS'] = 'No aplica'  # En aquellos indices identificados, asignar PIS = No aplica, pues los bloques de habitajes no tienen pisos\n", "ind_typos = df[df['US_EDIFICI'] == \"habitatge unifamiliar\"].index\n", "df.loc[ind_typos, 'PIS'] = 'No aplica'\n", "ind_typos = df[df['US_EDIFICI'] == \"terciari\"].index\n", "df.loc[ind_typos, 'PIS'] = 'No aplica'\n", "index_null = df[df[\"PIS\"].isnull()].index  # Identificar \u00c3\u00adndices de observaciones con PIS = NaN\n", "df = df.drop(index_null, axis=0)  # Eliminar observaciones con PIS = NaN\n", "ind_typos = df[df['PIS'] == \"-\"].index  # Identificar \u00c3\u00adndices de observaciones con PIS = -\n", "df = df.drop(ind_typos, axis=0)  # Eliminar observaciones con PIS = -\n", "value_counts = df['PIS'].value_counts(dropna=False)\n", "to_remove = value_counts[value_counts <= 100].index\n", "df = df[~df.PIS.isin(to_remove)]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ind_typos = df[df['PIS'] == '1\u00c2\u00ba'].index\n", "df.loc[ind_typos, 'PIS'] = '1'\n", "ind_typos = df[df['PIS'] == '1r'].index\n", "df.loc[ind_typos, 'PIS'] = '1'\n", "ind_typos = df[df['PIS'] == '01'].index\n", "df.loc[ind_typos, 'PIS'] = '1'\n", "ind_typos = df[df['PIS'] == '1er'].index\n", "df.loc[ind_typos, 'PIS'] = '1'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["TODO: Errores de formato en direcciones, n\u00c3\u00bameros, \u00e2\u20ac\u00a6"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO DE TRATAMIENTO COMPLETO DE UNA VARIABLE: Limpieza de CODI_POSTAL"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['CODI_POSTAL'].dtypes  # Comprobar el tipo de datos de la variable CODI_POSTAL"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["index_null = df[df[\"CODI_POSTAL\"].isnull()].index  # Identificar \u00c3\u00adndices de observaciones con CODI_POSTAL = NaN\n", "df = df.drop(index_null, axis=0)  # Eliminar observaciones con CODI_POSTAL = NaN"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['CODI_POSTAL'] = df['CODI_POSTAL'].astype(int)  # Convertir el tipo de datos de CODI_POSTAL a int\n", "df['CODI_POSTAL'] = df['CODI_POSTAL'].astype(str)  # Convertir el tipo de datos de CODI_POSTAL a str\n", "df['CODI_POSTAL'] = df['CODI_POSTAL'].str.zfill(5)  # Rellenar con ceros a la izquierda los valores de CODI_POSTAL hasta completar 5 d\u00c3\u00adgitos"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["col_name = \"CODI_POSTAL\"\n", "first_col = df.pop(col_name)\n", "df.insert(0, col_name, first_col)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO DE TRATAMIENTO COMPLETO DE UNA VARIABLE: Limpieza de Emissions de CO2 y Energia prim\u00c3\u00a0ria no renovable (la coma flotante hay que eliminarla)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[\"Emissions de CO2\"] = [float(str(i).replace(\",\", \"\")) for i in df[\"Emissions de CO2\"]]  # Eliminar la coma flotante de los valores de Emissions de CO2\n", "df[\"Energia prim\u00c3\u00a0ria no renovable\"] = [float(str(i).replace(\",\", \"\")) for i in df[\"Energia prim\u00c3\u00a0ria no renovable\"]]  # Eliminar la coma flotante de los valores de Energia prim\u00c3\u00a0ria no renovable"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO DE TRATAMIENTO COMPLETO DE UNA VARIABLE: Limpieza de VALOR FINESTRES CTE y<br>\n", "VALOR AILLAMENT CTE Para que se pandas detecte f\u00c3\u00a1cilmente que se trata de una var. categ\u00c3\u00b3rica."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['VALOR FINESTRES CTE'] = df['VALOR FINESTRES CTE'].astype(str)  # Convertir el tipo de datos de VALOR FINESTRES CTE a str\n", "df['VALOR AILLAMENTS CTE'] = df['VALOR AILLAMENTS CTE'].astype(str)  # Convertir el tipo de datos de VALOR AILLAMENTS CTE a str"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n S3.T3. Tratamiento de observaciones nulas (missing data)<br>\n", "\u00ef\u0192\u02dc Trata las observaciones NaNs de tu base de datos con adoptando la alternativa m\u00c3\u00a1s adiente en cada caso<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Diagn\u00c3\u00b3stico: Ver n\u00c2\u00ba NaNs en cada columna"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Num_Nans = np.sum(df[df.columns].isnull())  # N\u00c2\u00ba NaNs por columna"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Diagn\u00c3\u00b3stico: Ver radiograf\u00c3\u00ada de distribuci\u00c3\u00b3n de NaNs en cada observaci\u00c3\u00b3n (fila)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df2 = df.copy(deep=True)\n", "for col in df2.columns:\n", "    missing = df2[col].isnull()\n", "    num_missing = np.sum(missing)\n", "    if num_missing > 0:\n", "        df2['{}_ismissing'.format(col)] = missing\n", "ismissing_cols = [col for col in df2.columns if 'ismissing' in col]\n", "df2['num_missing'] = df2[ismissing_cols].sum(axis=1)\n", "missing_counts = df2['num_missing'].value_counts().reset_index()\n", "missing_counts.columns = ['num_missing', 'count']\n", "missing_counts.sort_values(by='num_missing', ascending=True, inplace=True)\n", "missing_counts.plot.bar(x='num_missing', y='count', legend=False)\n", "# Alternativa 1: Borrar filas con un n\u00c3\u00bamero elevado de NaNs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ind_ausentes = df2[df2['num_missing'] > 6].index  # Identificar \u00c3\u00adndices de observaciones con num_missing > 6\n", "df = df.drop(ind_ausentes, axis=0)  # Eliminar observaciones con num_missing > 6"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Alternativa 2: Borrar filas puntuales"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.drop([5], axis=0)  # Eliminar observaci\u00c3\u00b3n con \u00c3\u00adndice 5"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Alternativa 3: Borrar todas las filas que tengan un NaN en una determinada columna. Apropiado si hay muy pocos NaNs en la columna"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df[df['NOM_PROVINCIA'].notna()]  # Eliminar observaciones con NaN en la columna NOM_PROVINCIA"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Alternativa 4: Borrar columnas poco informativas que contengan observaciones nulas"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["100*np.mean(df[df.columns[3]].isnull())  # Porcentaje de NaNs en la columna 3\n", "df = df.drop(df.columns[3], axis=1)  # Eliminar columna 3"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Alternativa 5: Asignar un valor a la observaci\u00c3\u00b3n nula. Distintos casos seg\u00c3\u00ban variables cont\u00c3\u00adnuas o categ\u00c3\u00b3ricas"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["med = df['METRES_CADASTRE'].median()  # Calcular la mediana de la variable METRES_CADASTRE\n", "df['METRES_CADASTRE'] = df['METRES_CADASTRE'].fillna(med)  # Sustituimos NaNs por la mediana"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["top = df['SISTEMA BIOMASSA'].describe()['top']  # Calcular el valor m\u00c3\u00a1s frecuente de la variable SISTEMA BIOMASSA\n", "df['SISTEMA BIOMASSA'] = df['SISTEMA BIOMASSA'].fillna(top)  # Sustituimos NaNs por el campo m\u00c3\u00a1s com\u00c3\u00ban"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['XARXA DISTRICTE'] = df['XARXA DISTRICTE'].fillna('MISSING')  # Sustituimos NaNs una categor\u00c3\u00ada nueva"]}, {"cell_type": "markdown", "metadata": {}, "source": ["TAREA: Trata las observaciones NaNs de tu base de datos con adoptando la alternativa m\u00c3\u00a1s adiente en cada caso.<br>\n", "A\u00c3\u00b1ade comentarios explicando tu decisi\u00c3\u00b3n."]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO Limpieza de ZONA CLIMATICA."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_missing = np.sum(df[\"ZONA CLIMATICA\"].isnull())\n", "df = df[df['ZONA CLIMATICA'].notna()]  # C\u00c3\u00b3mo solo tengo 46 NaNs, elimino las observaciones asociadas"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["col_name = \"ZONA CLIMATICA\"\n", "first_col = df.pop(col_name)\n", "df.insert(0, col_name, first_col)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n S3.T4. Tratamiento de outliers<br>\n", "\u00ef\u0192\u02dc Elimina los outliers de tu base de datos de las variables continuas<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO: Identificaci\u00c3\u00b3n de outliers en variables cont\u00c3\u00adnuas"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['METRES_CADASTRE'].describe()  # Descripci\u00c3\u00b3n de la variable METRES_CADASTRE"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import seaborn as sns  # Gr\u00c3\u00a1fica de caja y bigotes\n", "sns.kdeplot(data=[df['METRES_CADASTRE']])  # Gr\u00c3\u00a1fico de densidad de la variable METRES_CADASTRE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO: Eliminar observaciones con outliers en variables cont\u00c3\u00adnuas"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ind_out = df[df['METRES_CADASTRE'] < 5].index  # Identificar \u00c3\u00adndices de observaciones con METRES_CADASTRE < 5 m\u00c2\u00b2\n", "df = df.drop(ind_out, axis=0)  # Eliminar observaciones con METRES_CADASTRE < 5 m\u00c2\u00b2\n", "ind_outliers = df[df['METRES_CADASTRE'] > 500].index  # Identificar \u00c3\u00adndices de observaciones con METRES_CADASTRE > 500 m\u00c2\u00b2\n", "df = df.drop(ind_outliers, axis=0)  # Eliminar observaciones con METRES_CADASTRE > 500 m\u00c2\u00b2\n", "col_name = \"METRES_CADASTRE\"\n", "first_col = df.pop(col_name)\n", "df.insert(0, col_name, first_col)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO: Identificaci\u00c3\u00b3n de outliers en variables categ\u00c3\u00b3ricas"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['US_EDIFICI'].value_counts().plot.bar()  # Gr\u00c3\u00a1fico de barras de la variable US_EDIFICI"]}, {"cell_type": "markdown", "metadata": {}, "source": ["EJEMPLO: Eliminar observaciones con outliers en variables categ\u00c3\u00b3ricas"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ind_out = df[df['US_EDIFICI'] == 'MULTIUSOS'].index  # Identificar \u00c3\u00adndices de observaciones con US_EDIFICI = 'MULTIUSOS'\n", "df = df.drop(ind_out, axis=0)  # Eliminar observaciones con US_EDIFICI = 'MULTIUSOS'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["TAREA: Elimina los outliers de tu base de datos (compacitat, Emissions de CO2, Energia prim\u00c3\u00a0ria no renovable)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["TODO: Eliminar observaciones duplicadas."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df.drop_duplicates()  # Eliminar observaciones duplicadas"]}, {"cell_type": "markdown", "metadata": {}, "source": ["TODO: Guardar BBDD"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.to_csv(r'G:\\Mi unidad\\Docencia\\Repo_projectes1\\BBDD_ST3.csv', index=False)  # Guardar BBDD"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nTAREAS FINALES SESI\u00c3\u201cN TRABAJO 3<br>\n", "DESCRIPCI\u00c3\u201cN DE LA TAREA: Contesta a las siguientes preguntas sobre tu nueva base de datos<br>\n", "\u00ef\u0192\u02dcN\u00c3\u00bamero de filas antes y despu\u00c3\u00a9s de la limpieza?<br>\n", "\u00ef\u0192\u02dcN\u00c3\u00bamero de columnas antes y despu\u00c3\u00a9s de la limpieza?<br>\n", "\u00ef\u0192\u02dcNombre de las columnas que usar\u00c3\u00a1s como posibles INPUTS (Entradas) en el proceso de certificaci\u00c3\u00b3n?<br>\n", "\u00ef\u0192\u02dcNombre de las columnas que usar\u00c3\u00a1s como posibles OUTPUTS (Salidas) del proceso de certificaci\u00c3\u00b3n?<br>\n", "\u00ef\u0192\u02dcEn las variables categ\u00c3\u00b3ricas, indicad el n\u00c3\u00bamero de campos posibles antes y despu\u00c3\u00a9s de la limpieza<br>\n", "\u00ef\u0192\u02dcEn las variables continuas, indicad la distribuci\u00c3\u00b3n inicial y final de los valores num\u00c3\u00a9ricos (con un kdeplot)<br>\n", ""]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}