{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vLfYKts35pb"
      },
      "source": [
        "# Sesión de Trabajo 3: LIMPIEZA DE LA BASE DE DATOS\n",
        "**Asignatura:** Ciència de Dades i Intel·ligència Artificial Aplicades a la Construcció i Estructures  \n",
        "**Institución:** ETSEIB - UPC  \n",
        "\n",
        "---\n",
        "\n",
        "## Objetivos de la sesión\n",
        "Antes de usar modelos estadísticos o de aprendizaje autónomo, siempre tenemos que limpiar los datos. Ningún modelo produce resultados significativos con datos sucios. En la sesión anterior, ya hicimos el primer paso para realizar la limpieza: detectar aquellas variables que requieren de correcciones. La sesión de trabajo actual se centra en corregir/rellenar/eliminar aquellos datos incorrectos/innecesarios/inconsistentes/nulos identificados perdiendo la mínima información posible. La sesión se estructura en diversas tareas.\n",
        "\n",
        "* **S3.T1.** Tratamiento de los datos no relevantes\n",
        "\n",
        "* **S3.T2.** Tratamiento de los datos inconsistentes\n",
        "\n",
        "* **S3.T3.** Tratamiento de las observaciones nulas (missing data)\n",
        "\n",
        "* **S3.T4.** Tratamiento de las observaciones atípicas (outliers)\n",
        "\n",
        "No existe un orden ni estrategia establecida para encarar esta tarea. En general, se intenta empezar por aquellas acciones más simples y de mayor impacto y poco a poco se va hacia las acciones más específicas.\n",
        "El objetivo es claro: obtener una BBDD relevante, consistente y sin observaciones nulas ni atípicas que sea lo más completa posible. Hay muchos caminos alternativos para alcanzarlo.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qC1U7pG35pj"
      },
      "source": [
        "### S3.T0. Importar la base de datos\n",
        "* Conectamos con Google Drive.\n",
        "* Cargamos el archivo `BBDD_ST2.csv`.\n",
        "* Optimizamos los tipos de datos (`float32` e `int32`) para no saturar la RAM de Colab.\n",
        "\n",
        "⏳ *Tiempo de ejecución estimado: 1-2 minutos (dependiendo de la velocidad de conexión a Drive).*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV_5NxsI35pl"
      },
      "outputs": [],
      "source": [
        "# Importar librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Montar Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Ruta y Carga\n",
        "ruta_drive = '/content/drive/MyDrive/Sostenibilidad/BBDD_ST2.csv'\n",
        "df = pd.read_csv(ruta_drive, low_memory=False)\n",
        "\n",
        "# Optimización\n",
        "float64_cols = df.select_dtypes(include='float64').columns.tolist()\n",
        "df[float64_cols] = df[float64_cols].astype('float32')\n",
        "int64_cols = df.select_dtypes(include='int64').columns.tolist()\n",
        "df[int64_cols] = df[int64_cols].astype('int32')\n",
        "\n",
        "print(\"Base de datos cargada y optimizada.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5DGJYzx35pn"
      },
      "source": [
        "---\n",
        "\n",
        "### S3.T1. Tratamiento de datos NO RELEVANTES\n",
        "\n",
        "* **S3.T1.1.** Identificar y Eliminar columnas no informativas debido a su alta repetitividad de sus observaciones.\n",
        "* **S3.T1.2.** Identificar y Eliminar columnas no informativas debido a su nula relación con el fenómeno de estudio.\n",
        "* **S3.T1.3.** Eliminar observaciones duplicadas. Esto se debería hacer al final de la limpieza de la BBDD.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJtGkY1J35po"
      },
      "source": [
        "* **S3.T1.1.** Identificar y Eliminar columnas no informativas debido a su alta repetitividad de sus observaciones.\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GohWZ0YX35pp"
      },
      "source": [
        ">>EJEMPLO: Columnas no informativas por repetición de valores o NaNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEyBde1n35pq"
      },
      "outputs": [],
      "source": [
        "df['SOLAR TERMICA'].value_counts(dropna=False) * 100 / len(df.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>EJEMPLO: Variables con pocos datos pero valiosos. Antes de eliminar una variable, mejor analizar su distribución con atención y asegurar que no aporta información relevante para el fenómeno de estudio"
      ],
      "metadata": {
        "id": "EyMEWYuC_CSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Preparación de datos\n",
        "ind_ve = df[df['VEHICLE ELECTRIC'] == 'SI'].index\n",
        "data_ve = df.loc[ind_ve, \"Qualificació de consum d'energia primaria no renovable\"].value_counts(normalize=True, dropna=False).sort_index()\n",
        "data_global = df[\"Qualificació de consum d'energia primaria no renovable\"].value_counts(normalize=True, dropna=False).sort_index()\n",
        "\n",
        "# 2. Definir una paleta de colores fija para que las letras (A, B, C...) coincidan siempre\n",
        "# Usamos un mapa de colores 'RdYlGn' (Rojo-Amarillo-Verde) invertido para eficiencia energética\n",
        "colores = plt.cm.RdYlGn_r(np.linspace(0, 1, len(data_global)))\n",
        "\n",
        "# 3. Crear la figura con 1 fila y 2 columnas\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Gráfico 1: Subgrupo con Vehículo Eléctrico\n",
        "data_ve.plot(\n",
        "    kind=\"pie\",\n",
        "    ax=ax1,\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    colors=colores,\n",
        "    wedgeprops={'edgecolor': 'white'}\n",
        ")\n",
        "ax1.set_title(\"Edificios con VEHÍCULO ELÉCTRICO\\n(Submuestreo)\", fontweight='bold')\n",
        "ax1.set_ylabel(\"\") # Elimina el texto lateral innecesario\n",
        "\n",
        "# Gráfico 2: Distribución Global\n",
        "data_global.plot(\n",
        "    kind=\"pie\",\n",
        "    ax=ax2,\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    colors=colores,\n",
        "    wedgeprops={'edgecolor': 'white'}\n",
        ")\n",
        "ax2.set_title(\"Distribución GLOBAL de la BBDD\\n(Población Total)\", fontweight='bold')\n",
        "ax2.set_ylabel(\"\")"
      ],
      "metadata": {
        "id": "PXgx2xOS_OXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>*TAREA: Completa la definición de la variable \"cols_baja_varianza\" con las variables (columnas) que tienen falta de variabilidad (Repetitividad o NaNs).*\n",
        "\n",
        ">>*Criterio: Columnas con >95% de valores idénticos o nulos.*"
      ],
      "metadata": {
        "id": "eI2YnPxC9Lpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_baja_varianza = [\n",
        "    'SOLAR TERMICA',              # 100% \"NO\"\n",
        "    'INFORME_INS_TECNICA_EDIFICI', # 99.83 % NaN\n",
        "    # ... Añade aquí el resto de variables, poniendo al lado el motivo de su inclusión ...\n",
        "]"
      ],
      "metadata": {
        "id": "hm8p6OVo9aTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-SSXgRi35ps"
      },
      "source": [
        ">>Eliminar columnas no informativas por repetición de valores o NaNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "258XuvsK35pt"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=cols_baja_varianza, errors='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR1nv1FU35pz"
      },
      "source": [
        "* **S3.T1.2.** Identificar y Eliminar columnas no informativas debido a su nula relación con el fenómeno de estudio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5ximT8D35p3"
      },
      "outputs": [],
      "source": [
        "# Lista de variables a eliminar por nula relación\n",
        "cols_no_relacionadas = [\n",
        "    'NUM_CAS',              # ID administrativo de la Generalitat\n",
        "    'REFERENCIA CADASTRAL', # No influye en la física del edificio\n",
        "    # --- Añade aquí el resto de variables detectadas ---\n",
        "]\n",
        "\n",
        "# Ejecución de la eliminación\n",
        "df = df.drop(columns=cols_no_relacionadas, errors='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **S3.T1.3.** Eliminar observaciones duplicadas. Esto se debería repetir al final de la limpieza de la BBDD."
      ],
      "metadata": {
        "id": "6iOBTCBkFo36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()  # Eliminar observaciones duplicadas"
      ],
      "metadata": {
        "id": "xXPV4tf4FxsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ta10_kD35p3"
      },
      "source": [
        "---\n",
        "\n",
        "### S3.T2. Tratamiento de datos INCONSISTENTES\n",
        "\n",
        "* **S3.T2.1.** Uniformizar uso de las mayúsculas/minúsculas y corregir errores de escritura en variables categóricas.\n",
        "* **S3.T2.2.** Errores de formato en direcciones, números, ...\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c7B7FzL35p3"
      },
      "source": [
        "TODO: Uniformizar uso de las mayÃºsculas/minÃºsculas y corregir errores de escritura en variables categÃ³ricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2coXWCUZ35p4"
      },
      "source": [
        "EJEMPLO: Uniformizar mayÃºsculas/minÃºsculas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DZii4Wc35p5"
      },
      "outputs": [],
      "source": [
        "df['NOM_PROVINCIA'].value_counts(dropna=False)  # DistribuciÃ³n de valores de NOM_PROVINCIA\n",
        "df['NOM_PROVINCIA'] = df['NOM_PROVINCIA'].str.lower()  # Convertir a minÃºsculas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwX1R5RP35p5"
      },
      "source": [
        "EJEMPLO: Corregir errores de escritura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1aalDaH35p6"
      },
      "outputs": [],
      "source": [
        "df['US_EDIFICI'].value_counts(dropna=False)  # DistribuciÃ³n de valores de US_EDIFICI\n",
        "ind_typos = df[df['US_EDIFICI'] == 'Terciario'].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = Terciario\n",
        "df.loc[ind_typos, 'US_EDIFICI'] = 'Terciari'  # Corregir US_EDIFICI = Terciario por Terciari"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCw9xq1i35p7"
      },
      "source": [
        "EJEMPLO: Eliminar observaciones con ciertas subcategorÃ­as errÃ³neas, pero que no tenemos criterio para corregir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVRQxk2435p8"
      },
      "outputs": [],
      "source": [
        "df['US_EDIFICI'].value_counts(dropna=False)  # DistribuciÃ³n de valores de US_EDIFICI\n",
        "ind_typos = df[df[\"US_EDIFICI\"] == \"Habitatge\"].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = Habitatge\n",
        "df.drop(ind_typos, axis=0)  # Eliminar observaciones con US_EDIFICI = Habitatge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eyEJSWT35p8"
      },
      "source": [
        "EJEMPLO: Variable que el esfuerzo para corregir estos aspectos puede ser NO ASUMIBLE para el beneficio que aporta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqmaEDdZ35p8"
      },
      "outputs": [],
      "source": [
        "df['POBLACIO'].value_counts(dropna=False)  # DistribuciÃ³n de valores de POBLACIO. Vemos hay que muchisimos valores errÃ³neos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZK0P0Y035p_"
      },
      "source": [
        "EJEMPLO DE TRATAMIENTO COMPLETO DE UNA VARIABLE: Limpieza de NOM_PROVINCIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtgJb75I35p_"
      },
      "outputs": [],
      "source": [
        "df['NOM_PROVINCIA'].value_counts(dropna=False)  # DistribuciÃ³n de valores de NOM_PROVINCIA\n",
        "df['NOM_PROVINCIA'] = df['NOM_PROVINCIA'].str.lower()  # Convertir a minÃºsculas\n",
        "ind_typos = df[df['NOM_PROVINCIA'] == '0'].index  # Identificar Ã­ndices de observaciones con NOM_PROVINCIA = 0\n",
        "df = df.drop(ind_typos, axis=0)  # Eliminar observaciones con NOM_PROVINCIA = 0. No podemos corregir pues no tenemos criterio.\n",
        "col_name = \"NOM_PROVINCIA\"  # Nombre de la variable a tratar\n",
        "first_col = df.pop(col_name)  # Extraer la variable a tratar de df\n",
        "df.insert(0, col_name, first_col)  # Insertar la variable a tratar en la primera posiciÃ³n de df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjBzOJ1R35qA"
      },
      "source": [
        "EJEMPLO DE TRATAMIENTO COMPLETO DE UNA VARIABLE: Limpieza de US_EDIFICI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1XsylCc35qA"
      },
      "outputs": [],
      "source": [
        "df['US_EDIFICI'].value_counts(dropna=False)  # DistribuciÃ³n de valores de US_EDIFICI\n",
        "df['US_EDIFICI'] = df['US_EDIFICI'].str.lower()  # Convertir a minÃºsculas\n",
        "ind_typos = df[df['US_EDIFICI'] == 'terciario'].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = terciario\n",
        "df.loc[ind_typos, 'US_EDIFICI'] = 'terciari'  # Corregir US_EDIFICI = terciario por terciari\n",
        "ind_typos = df[df['US_EDIFICI'] == 'vivienda individual en bloque de viviendas'].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = vivienda individual en bloque de viviendas\n",
        "df.loc[ind_typos, 'US_EDIFICI'] = \"habitatge individual en bloc d'habitatges\"  # Corregir US_EDIFICI = vivienda individual en bloque de viviendas por habitatge individual en bloc d'habitatges\n",
        "ind_typos = df[df['US_EDIFICI'] == 'vivienda unifamiliar'].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = vivienda unifamiliar\n",
        "df.loc[ind_typos, 'US_EDIFICI'] = \"habitatge unifamiliar\"  # Corregir US_EDIFICI = vivienda unifamiliar por habitatge unifamiliar\n",
        "ind_typos = df[df['US_EDIFICI'] == \"bloc d'habitatges\"].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = bloc d'habitatges\n",
        "df.loc[ind_typos, 'US_EDIFICI'] = \"bloc d'habitatges plurifamiliar\"  # Corregir US_EDIFICI = bloc d'habitatges por bloc d'habitatges plurifamiliar\n",
        "ind_typos = df[df['US_EDIFICI'] == \"bloque de viviendas\"].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = bloque de viviendas\n",
        "df.loc[ind_typos, 'US_EDIFICI'] = \"bloc d'habitatges plurifamiliar\"  # Corregir US_EDIFICI = bloque de viviendas por bloc d'habitatges plurifamiliar\n",
        "ind_typos = df[df['US_EDIFICI'] == \"habitatge plurifamiliar\"].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = habitatge plurifamiliar\n",
        "df.loc[ind_typos, 'US_EDIFICI'] = \"bloc d'habitatges plurifamiliar\"  # Corregir US_EDIFICI = habitatge plurifamiliar por bloc d'habitatges plurifamiliar\n",
        "ind_typos = df[df['US_EDIFICI'] == \"habitatge unifamiliar aÃ¯llat\"].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = habitatge unifamiliar aÃ¯llat\n",
        "df.loc[ind_typos, 'US_EDIFICI'] = \"habitatge unifamiliar\"  # Corregir US_EDIFICI = habitatge unifamiliar aÃ¯llat por habitatge unifamiliar\n",
        "ind_typos = df[df['US_EDIFICI'] == \"habitatge unifamiliar adossat\"].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = habitatge unifamiliar adossat\n",
        "df.loc[ind_typos, 'US_EDIFICI'] = \"habitatge unifamiliar\"  # Corregir US_EDIFICI = habitatge unifamiliar adossat por habitatge unifamiliar\n",
        "ind_typos = df[df['US_EDIFICI'] == \"bloque de viviendas plurifamiliar\"].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = bloque de viviendas plurifamiliar\n",
        "df.loc[ind_typos, 'US_EDIFICI'] = \"bloc d'habitatges plurifamiliar\"  # Corregir US_EDIFICI = bloque de viviendas plurifamiliar por bloc d'habitatges plurifamiliar\n",
        "ind_typos = df[df['US_EDIFICI'] == \"terciari: locals, oficines...\"].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = terciari: locals, oficines...\n",
        "df.loc[ind_typos, 'US_EDIFICI'] = \"terciari\"  # Corregir US_EDIFICI = terciari: locals, oficines... por terciari"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-FHpGIw35qC"
      },
      "outputs": [],
      "source": [
        "value_counts = df['US_EDIFICI'].value_counts(dropna=False)  # DistribuciÃ³n de valores de US_EDIFICI\n",
        "to_remove = value_counts[value_counts <= 400].index  # Identificar Ã­ndices de US_EDIFICI con menos de 400 observaciones\n",
        "df = df[~df.US_EDIFICI.isin(to_remove)]  # Eliminar observaciones con US_EDIFICI con menos de 400 observaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKJqcZl435qD"
      },
      "outputs": [],
      "source": [
        "col_name = \"US_EDIFICI\"  # Nombre de la variable a tratar\n",
        "first_col = df.pop(col_name)  # Extraer la variable a tratar de df\n",
        "df.insert(0, col_name, first_col)  # Insertar la variable a tratar en la primera posiciÃ³n de df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA4x-25n35qD"
      },
      "source": [
        "TAREA: Uniformiza el uso de mayÃºsculas/minÃºsculas y corrige los errores de escritura en variables categÃ³ricas.<br>\n",
        "Para facilitar la tarea, se os empieza la limpieza de las variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9BH80_A35qS"
      },
      "outputs": [],
      "source": [
        "    # Limpieza COMARCA. Continuar la lista..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHqAz3Mv35qU"
      },
      "outputs": [],
      "source": [
        "df['COMARCA'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LZC0dSf35qV"
      },
      "outputs": [],
      "source": [
        "ind_typos = df[df['COMARCA'] == \"BarcelonÃ©s\"].index\n",
        "df.loc[ind_typos, 'COMARCA'] = \"BarcelonÃ¨s\"\n",
        "ind_typos = df[df['COMARCA'] == \"BarcelonÂ¿s\"].index\n",
        "df.loc[ind_typos, 'COMARCA'] = \"BarcelonÃ¨s\"\n",
        "ind_typos = df[df['COMARCA'] == \"VallÃ½s Oriental\"].index\n",
        "df.loc[ind_typos, 'COMARCA'] = \"VallÃ¨s Oriental\"\n",
        "\n",
        "    # Limpieza de Eines de certificacio. Continuar la lista..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cAhHIiE35qV"
      },
      "outputs": [],
      "source": [
        "index_null = df[df[\"Eina de certificacio\"].isnull()].index\n",
        "df = df.drop(index_null, axis=0)\n",
        "ind_typos = df[df['Eina de certificacio'] == \"CE3x\"].index\n",
        "df.loc[ind_typos, 'Eina de certificacio'] = \"CE3X\"\n",
        "ind_typos = df[df['Eina de certificacio'] == \"CALENER VYP\"].index\n",
        "df.loc[ind_typos, 'Eina de certificacio'] = \"CALENER\"\n",
        "\n",
        "    # Limpieza Motiu de la certificacio. Continuar la lista..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORrIUcpd35qW"
      },
      "outputs": [],
      "source": [
        "df['Motiu de la certificacio'] = df['Motiu de la certificacio'].str.lower()\n",
        "ind_typos = df[df['Motiu de la certificacio'] == 'alquiler'].index\n",
        "df.loc[ind_typos, 'Motiu de la certificacio'] = 'lloguer'\n",
        "ind_typos = df[df['Motiu de la certificacio'] == 'compravenda'].index\n",
        "df.loc[ind_typos, 'Motiu de la certificacio'] = 'compra o venda'\n",
        "\n",
        "    # Limpieza Normativa construcciÃ³. Continuar la lista..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfawPIp535qX"
      },
      "outputs": [],
      "source": [
        "df['Normativa construcciÃ³'] = df['Normativa construcciÃ³'].str.lower()\n",
        "ind_typos = df[df['Normativa construcciÃ³'] == 'antes de 1979'].index\n",
        "df.loc[ind_typos, 'Normativa construcciÃ³'] = 'abans de 1979'\n",
        "\n",
        "    # Limpieza TITULACIO_TECNIC. Continuar la lista..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qUL1x3T35qY"
      },
      "outputs": [],
      "source": [
        "df['TITULACIO_TECNIC'] = df['TITULACIO_TECNIC'].str.lower()\n",
        "ind_typos = df[df['TITULACIO_TECNIC'] == 'arquitecto tÃ©cnico'].index\n",
        "df.loc[ind_typos, 'TITULACIO_TECNIC'] = 'arquitecte tÃ¨cnic'\n",
        "\n",
        "    # Limpieza PIS. Continuar la lista...(campos sugeridos: \"SOT\", \"BX\", \"EN\", \"PR\", \"1\", \"2\", \"3\", \"4\", \"5-9\", \">10\", \"AT\", \"SA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTOYymGB35qY"
      },
      "outputs": [],
      "source": [
        "ind_typos = df[df['US_EDIFICI'] == \"bloc d'habitatges plurifamiliar\"].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = bloc d'habitatges plurifamiliar\n",
        "df.loc[ind_typos, 'PIS'] = 'No aplica'  # En aquellos indices identificados, asignar PIS = No aplica, pues los bloques de habitajes no tienen pisos\n",
        "ind_typos = df[df['US_EDIFICI'] == \"habitatge unifamiliar\"].index\n",
        "df.loc[ind_typos, 'PIS'] = 'No aplica'\n",
        "ind_typos = df[df['US_EDIFICI'] == \"terciari\"].index\n",
        "df.loc[ind_typos, 'PIS'] = 'No aplica'\n",
        "index_null = df[df[\"PIS\"].isnull()].index  # Identificar Ã­ndices de observaciones con PIS = NaN\n",
        "df = df.drop(index_null, axis=0)  # Eliminar observaciones con PIS = NaN\n",
        "ind_typos = df[df['PIS'] == \"-\"].index  # Identificar Ã­ndices de observaciones con PIS = -\n",
        "df = df.drop(ind_typos, axis=0)  # Eliminar observaciones con PIS = -\n",
        "value_counts = df['PIS'].value_counts(dropna=False)\n",
        "to_remove = value_counts[value_counts <= 100].index\n",
        "df = df[~df.PIS.isin(to_remove)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49Hb3iaY35qa"
      },
      "outputs": [],
      "source": [
        "ind_typos = df[df['PIS'] == '1Âº'].index\n",
        "df.loc[ind_typos, 'PIS'] = '1'\n",
        "ind_typos = df[df['PIS'] == '1r'].index\n",
        "df.loc[ind_typos, 'PIS'] = '1'\n",
        "ind_typos = df[df['PIS'] == '01'].index\n",
        "df.loc[ind_typos, 'PIS'] = '1'\n",
        "ind_typos = df[df['PIS'] == '1er'].index\n",
        "df.loc[ind_typos, 'PIS'] = '1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InR2ItDx35qa"
      },
      "source": [
        "TODO: Errores de formato en direcciones, nÃºmeros, â€¦"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4rOsFft35qb"
      },
      "source": [
        "EJEMPLO DE TRATAMIENTO COMPLETO DE UNA VARIABLE: Limpieza de CODI_POSTAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHkCnuUN35qc"
      },
      "outputs": [],
      "source": [
        "df['CODI_POSTAL'].dtypes  # Comprobar el tipo de datos de la variable CODI_POSTAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqQ6LGLt35qd"
      },
      "outputs": [],
      "source": [
        "index_null = df[df[\"CODI_POSTAL\"].isnull()].index  # Identificar Ã­ndices de observaciones con CODI_POSTAL = NaN\n",
        "df = df.drop(index_null, axis=0)  # Eliminar observaciones con CODI_POSTAL = NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl-0Hzu935qe"
      },
      "outputs": [],
      "source": [
        "df['CODI_POSTAL'] = df['CODI_POSTAL'].astype(int)  # Convertir el tipo de datos de CODI_POSTAL a int\n",
        "df['CODI_POSTAL'] = df['CODI_POSTAL'].astype(str)  # Convertir el tipo de datos de CODI_POSTAL a str\n",
        "df['CODI_POSTAL'] = df['CODI_POSTAL'].str.zfill(5)  # Rellenar con ceros a la izquierda los valores de CODI_POSTAL hasta completar 5 dÃ­gitos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1Ijj8C-35qf"
      },
      "outputs": [],
      "source": [
        "col_name = \"CODI_POSTAL\"\n",
        "first_col = df.pop(col_name)\n",
        "df.insert(0, col_name, first_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKuKILDe35qg"
      },
      "source": [
        "EJEMPLO DE TRATAMIENTO COMPLETO DE UNA VARIABLE: Limpieza de Emissions de CO2 y Energia primÃ ria no renovable (la coma flotante hay que eliminarla)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNgcy6lg35qh"
      },
      "outputs": [],
      "source": [
        "df[\"Emissions de CO2\"] = [float(str(i).replace(\",\", \"\")) for i in df[\"Emissions de CO2\"]]  # Eliminar la coma flotante de los valores de Emissions de CO2\n",
        "df[\"Energia primÃ ria no renovable\"] = [float(str(i).replace(\",\", \"\")) for i in df[\"Energia primÃ ria no renovable\"]]  # Eliminar la coma flotante de los valores de Energia primÃ ria no renovable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF9sD7a835qj"
      },
      "source": [
        "EJEMPLO DE TRATAMIENTO COMPLETO DE UNA VARIABLE: Limpieza de VALOR FINESTRES CTE y<br>\n",
        "VALOR AILLAMENT CTE Para que se pandas detecte fÃ¡cilmente que se trata de una var. categÃ³rica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_j0Xw2R35qk"
      },
      "outputs": [],
      "source": [
        "df['VALOR FINESTRES CTE'] = df['VALOR FINESTRES CTE'].astype(str)  # Convertir el tipo de datos de VALOR FINESTRES CTE a str\n",
        "df['VALOR AILLAMENTS CTE'] = df['VALOR AILLAMENTS CTE'].astype(str)  # Convertir el tipo de datos de VALOR AILLAMENTS CTE a str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afhj8MHB35ql"
      },
      "source": [
        "\n",
        " S3.T3. Tratamiento de observaciones nulas (missing data)<br>\n",
        "ïƒ˜ Trata las observaciones NaNs de tu base de datos con adoptando la alternativa mÃ¡s adiente en cada caso<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3PMlcAw35ql"
      },
      "source": [
        "DiagnÃ³stico: Ver nÂº NaNs en cada columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqVePxvb35ql"
      },
      "outputs": [],
      "source": [
        "Num_Nans = np.sum(df[df.columns].isnull())  # NÂº NaNs por columna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQXQCOiC35qm"
      },
      "source": [
        "DiagnÃ³stico: Ver radiografÃ­a de distribuciÃ³n de NaNs en cada observaciÃ³n (fila)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ra4UHuO35qn"
      },
      "outputs": [],
      "source": [
        "df2 = df.copy(deep=True)\n",
        "for col in df2.columns:\n",
        "    missing = df2[col].isnull()\n",
        "    num_missing = np.sum(missing)\n",
        "    if num_missing > 0:\n",
        "        df2['{}_ismissing'.format(col)] = missing\n",
        "ismissing_cols = [col for col in df2.columns if 'ismissing' in col]\n",
        "df2['num_missing'] = df2[ismissing_cols].sum(axis=1)\n",
        "missing_counts = df2['num_missing'].value_counts().reset_index()\n",
        "missing_counts.columns = ['num_missing', 'count']\n",
        "missing_counts.sort_values(by='num_missing', ascending=True, inplace=True)\n",
        "missing_counts.plot.bar(x='num_missing', y='count', legend=False)\n",
        "# Alternativa 1: Borrar filas con un nÃºmero elevado de NaNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6GSMpGr35qo"
      },
      "outputs": [],
      "source": [
        "ind_ausentes = df2[df2['num_missing'] > 6].index  # Identificar Ã­ndices de observaciones con num_missing > 6\n",
        "df = df.drop(ind_ausentes, axis=0)  # Eliminar observaciones con num_missing > 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM1YQwbn35qp"
      },
      "source": [
        "Alternativa 2: Borrar filas puntuales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9KZLLud35qq"
      },
      "outputs": [],
      "source": [
        "df.drop([5], axis=0)  # Eliminar observaciÃ³n con Ã­ndice 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_PWbTBq35qq"
      },
      "source": [
        "Alternativa 3: Borrar todas las filas que tengan un NaN en una determinada columna. Apropiado si hay muy pocos NaNs en la columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6_Jdvtq35qr"
      },
      "outputs": [],
      "source": [
        "df = df[df['NOM_PROVINCIA'].notna()]  # Eliminar observaciones con NaN en la columna NOM_PROVINCIA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlajGpFU35qr"
      },
      "source": [
        "Alternativa 4: Borrar columnas poco informativas que contengan observaciones nulas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9uhzqZ735qs"
      },
      "outputs": [],
      "source": [
        "100*np.mean(df[df.columns[3]].isnull())  # Porcentaje de NaNs en la columna 3\n",
        "df = df.drop(df.columns[3], axis=1)  # Eliminar columna 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrsQ1N0635qt"
      },
      "source": [
        "Alternativa 5: Asignar un valor a la observaciÃ³n nula. Distintos casos segÃºn variables contÃ­nuas o categÃ³ricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diDElvcU35qu"
      },
      "outputs": [],
      "source": [
        "med = df['METRES_CADASTRE'].median()  # Calcular la mediana de la variable METRES_CADASTRE\n",
        "df['METRES_CADASTRE'] = df['METRES_CADASTRE'].fillna(med)  # Sustituimos NaNs por la mediana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amEXtUKu35qu"
      },
      "outputs": [],
      "source": [
        "top = df['SISTEMA BIOMASSA'].describe()['top']  # Calcular el valor mÃ¡s frecuente de la variable SISTEMA BIOMASSA\n",
        "df['SISTEMA BIOMASSA'] = df['SISTEMA BIOMASSA'].fillna(top)  # Sustituimos NaNs por el campo mÃ¡s comÃºn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Qrd9bT35qv"
      },
      "outputs": [],
      "source": [
        "df['XARXA DISTRICTE'] = df['XARXA DISTRICTE'].fillna('MISSING')  # Sustituimos NaNs una categorÃ­a nueva"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2oZlaYB35qw"
      },
      "source": [
        "TAREA: Trata las observaciones NaNs de tu base de datos con adoptando la alternativa mÃ¡s adiente en cada caso.<br>\n",
        "AÃ±ade comentarios explicando tu decisiÃ³n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUwzJgpJ35qw"
      },
      "source": [
        "EJEMPLO Limpieza de ZONA CLIMATICA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbUaxc6C35qx"
      },
      "outputs": [],
      "source": [
        "num_missing = np.sum(df[\"ZONA CLIMATICA\"].isnull())\n",
        "df = df[df['ZONA CLIMATICA'].notna()]  # CÃ³mo solo tengo 46 NaNs, elimino las observaciones asociadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PY_ERUdK35q0"
      },
      "outputs": [],
      "source": [
        "col_name = \"ZONA CLIMATICA\"\n",
        "first_col = df.pop(col_name)\n",
        "df.insert(0, col_name, first_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bECQsmq-35q1"
      },
      "source": [
        "\n",
        " S3.T4. Tratamiento de outliers<br>\n",
        "ïƒ˜ Elimina los outliers de tu base de datos de las variables continuas<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5So92tM35q2"
      },
      "source": [
        "EJEMPLO: IdentificaciÃ³n de outliers en variables contÃ­nuas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2DUlNTD35q3"
      },
      "outputs": [],
      "source": [
        "df['METRES_CADASTRE'].describe()  # DescripciÃ³n de la variable METRES_CADASTRE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQryi0NY35q3"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns  # GrÃ¡fica de caja y bigotes\n",
        "sns.kdeplot(data=[df['METRES_CADASTRE']])  # GrÃ¡fico de densidad de la variable METRES_CADASTRE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MAadRav35q4"
      },
      "source": [
        "EJEMPLO: Eliminar observaciones con outliers en variables contÃ­nuas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHrybjZN35q5"
      },
      "outputs": [],
      "source": [
        "ind_out = df[df['METRES_CADASTRE'] < 5].index  # Identificar Ã­ndices de observaciones con METRES_CADASTRE < 5 mÂ²\n",
        "df = df.drop(ind_out, axis=0)  # Eliminar observaciones con METRES_CADASTRE < 5 mÂ²\n",
        "ind_outliers = df[df['METRES_CADASTRE'] > 500].index  # Identificar Ã­ndices de observaciones con METRES_CADASTRE > 500 mÂ²\n",
        "df = df.drop(ind_outliers, axis=0)  # Eliminar observaciones con METRES_CADASTRE > 500 mÂ²\n",
        "col_name = \"METRES_CADASTRE\"\n",
        "first_col = df.pop(col_name)\n",
        "df.insert(0, col_name, first_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIk5SGJO35q6"
      },
      "source": [
        "EJEMPLO: IdentificaciÃ³n de outliers en variables categÃ³ricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDuPyT8935q8"
      },
      "outputs": [],
      "source": [
        "df['US_EDIFICI'].value_counts().plot.bar()  # GrÃ¡fico de barras de la variable US_EDIFICI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnEJrynp35q8"
      },
      "source": [
        "EJEMPLO: Eliminar observaciones con outliers en variables categÃ³ricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Yxx5XZc35q9"
      },
      "outputs": [],
      "source": [
        "ind_out = df[df['US_EDIFICI'] == 'MULTIUSOS'].index  # Identificar Ã­ndices de observaciones con US_EDIFICI = 'MULTIUSOS'\n",
        "df = df.drop(ind_out, axis=0)  # Eliminar observaciones con US_EDIFICI = 'MULTIUSOS'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT-Ug_ib35q-"
      },
      "source": [
        "TAREA: Elimina los outliers de tu base de datos (compacitat, Emissions de CO2, Energia primÃ ria no renovable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4GgyxqM35q_"
      },
      "source": [
        "TODO: Eliminar observaciones duplicadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rONJCqct35q_"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates()  # Eliminar observaciones duplicadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqUh6M3735rA"
      },
      "source": [
        "TODO: Guardar BBDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFQYpSox35rB"
      },
      "outputs": [],
      "source": [
        "df.to_csv(r'G:\\Mi unidad\\Docencia\\Repo_projectes1\\BBDD_ST3.csv', index=False)  # Guardar BBDD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpSfc0PP35rB"
      },
      "source": [
        "\n",
        "TAREAS FINALES SESIÃ“N TRABAJO 3<br>\n",
        "DESCRIPCIÃ“N DE LA TAREA: Contesta a las siguientes preguntas sobre tu nueva base de datos<br>\n",
        "ïƒ˜NÃºmero de filas antes y despuÃ©s de la limpieza?<br>\n",
        "ïƒ˜NÃºmero de columnas antes y despuÃ©s de la limpieza?<br>\n",
        "ïƒ˜Nombre de las columnas que usarÃ¡s como posibles INPUTS (Entradas) en el proceso de certificaciÃ³n?<br>\n",
        "ïƒ˜Nombre de las columnas que usarÃ¡s como posibles OUTPUTS (Salidas) del proceso de certificaciÃ³n?<br>\n",
        "ïƒ˜En las variables categÃ³ricas, indicad el nÃºmero de campos posibles antes y despuÃ©s de la limpieza<br>\n",
        "ïƒ˜En las variables continuas, indicad la distribuciÃ³n inicial y final de los valores numÃ©ricos (con un kdeplot)<br>\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}