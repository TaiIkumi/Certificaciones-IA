{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vLfYKts35pb"
      },
      "source": [
        "# Sesi√≥n de Trabajo 3: LIMPIEZA DE LA BASE DE DATOS\n",
        "**Asignatura:** Ci√®ncia de Dades i Intel¬∑lig√®ncia Artificial Aplicades a la Construcci√≥ i Estructures  \n",
        "**Instituci√≥n:** ETSEIB - UPC  \n",
        "\n",
        "---\n",
        "\n",
        "## Objetivos de la sesi√≥n\n",
        "Antes de usar modelos estad√≠sticos o de aprendizaje aut√≥nomo, siempre tenemos que limpiar los datos. Ning√∫n modelo produce resultados significativos con datos sucios. En la sesi√≥n anterior, ya hicimos el primer paso para realizar la limpieza: detectar aquellas variables que requieren de correcciones. La sesi√≥n de trabajo actual se centra en corregir/rellenar/eliminar aquellos datos incorrectos/innecesarios/inconsistentes/nulos identificados perdiendo la m√≠nima informaci√≥n posible. La sesi√≥n se estructura en diversas tareas.\n",
        "\n",
        "* **S3.T1.** Tratamiento de los datos no relevantes\n",
        "\n",
        "* **S3.T2.** Tratamiento de los datos inconsistentes\n",
        "\n",
        "* **S3.T3.** Tratamiento de las observaciones nulas (missing data)\n",
        "\n",
        "* **S3.T4.** Tratamiento de las observaciones at√≠picas (outliers)\n",
        "\n",
        "No existe un orden ni estrategia establecida para encarar esta tarea. En general, se intenta empezar por aquellas acciones m√°s simples y de mayor impacto y poco a poco se va hacia las acciones m√°s espec√≠ficas.\n",
        "El objetivo es claro: obtener una BBDD relevante, consistente y sin observaciones nulas ni at√≠picas que sea lo m√°s completa posible. Hay muchos caminos alternativos para alcanzarlo.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qC1U7pG35pj"
      },
      "source": [
        "### S3.T0. Importar la base de datos\n",
        "* Conectamos con Google Drive.\n",
        "* Cargamos el archivo `BBDD_ST2.csv`.\n",
        "* Optimizamos los tipos de datos (`float32` e `int32`) para no saturar la RAM de Colab.\n",
        "\n",
        "‚è≥ *Tiempo de ejecuci√≥n estimado: 1-2 minutos (dependiendo de la velocidad de conexi√≥n a Drive).*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV_5NxsI35pl"
      },
      "outputs": [],
      "source": [
        "# Importar librer√≠as\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Montar Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Ruta y Carga\n",
        "ruta_drive = '/content/drive/MyDrive/Sostenibilidad/BBDD_ST2.csv'\n",
        "df = pd.read_csv(ruta_drive, low_memory=False)\n",
        "\n",
        "# Optimizaci√≥n\n",
        "float64_cols = df.select_dtypes(include='float64').columns.tolist()\n",
        "df[float64_cols] = df[float64_cols].astype('float32')\n",
        "int64_cols = df.select_dtypes(include='int64').columns.tolist()\n",
        "df[int64_cols] = df[int64_cols].astype('int32')\n",
        "\n",
        "print(\"Base de datos cargada y optimizada.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5DGJYzx35pn"
      },
      "source": [
        "---\n",
        "\n",
        "### S3.T1. Tratamiento de datos NO RELEVANTES\n",
        "\n",
        "* **S3.T1.1.** Identificar y Eliminar columnas no informativas debido a su alta repetitividad de sus observaciones.\n",
        "* **S3.T1.2.** Identificar y Eliminar columnas no informativas debido a su nula relaci√≥n con el fen√≥meno de estudio.\n",
        "* **S3.T1.3.** Eliminar observaciones duplicadas. Esto se deber√≠a hacer al final de la limpieza de la BBDD.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJtGkY1J35po"
      },
      "source": [
        "* **S3.T1.1.** Identificar y Eliminar columnas no informativas debido a su alta repetitividad de sus observaciones.\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GohWZ0YX35pp"
      },
      "source": [
        ">>EJEMPLO: Columnas no informativas por repetici√≥n de valores o NaNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEyBde1n35pq"
      },
      "outputs": [],
      "source": [
        "df['SOLAR TERMICA'].value_counts(dropna=False) * 100 / len(df.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>EJEMPLO: Variables con pocos datos pero valiosos. Antes de eliminar una variable, mejor analizar su distribuci√≥n con atenci√≥n y asegurar que no aporta informaci√≥n relevante para el fen√≥meno de estudio"
      ],
      "metadata": {
        "id": "EyMEWYuC_CSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Preparaci√≥n de datos\n",
        "ind_ve = df[df['VEHICLE ELECTRIC'] == 'SI'].index\n",
        "data_ve = df.loc[ind_ve, \"Qualificaci√≥ de consum d'energia primaria no renovable\"].value_counts(normalize=True, dropna=False).sort_index()\n",
        "data_global = df[\"Qualificaci√≥ de consum d'energia primaria no renovable\"].value_counts(normalize=True, dropna=False).sort_index()\n",
        "\n",
        "# 2. Definir una paleta de colores fija para que las letras (A, B, C...) coincidan siempre\n",
        "# Usamos un mapa de colores 'RdYlGn' (Rojo-Amarillo-Verde) invertido para eficiencia energ√©tica\n",
        "colores = plt.cm.RdYlGn_r(np.linspace(0, 1, len(data_global)))\n",
        "\n",
        "# 3. Crear la figura con 1 fila y 2 columnas\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Gr√°fico 1: Subgrupo con Veh√≠culo El√©ctrico\n",
        "data_ve.plot(\n",
        "    kind=\"pie\",\n",
        "    ax=ax1,\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    colors=colores,\n",
        "    wedgeprops={'edgecolor': 'white'}\n",
        ")\n",
        "ax1.set_title(\"Edificios con VEH√çCULO EL√âCTRICO\\n(Submuestreo)\", fontweight='bold')\n",
        "ax1.set_ylabel(\"\") # Elimina el texto lateral innecesario\n",
        "\n",
        "# Gr√°fico 2: Distribuci√≥n Global\n",
        "data_global.plot(\n",
        "    kind=\"pie\",\n",
        "    ax=ax2,\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    colors=colores,\n",
        "    wedgeprops={'edgecolor': 'white'}\n",
        ")\n",
        "ax2.set_title(\"Distribuci√≥n GLOBAL de la BBDD\\n(Poblaci√≥n Total)\", fontweight='bold')\n",
        "ax2.set_ylabel(\"\")"
      ],
      "metadata": {
        "id": "PXgx2xOS_OXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>*TAREA: Completa la definici√≥n de la variable \"cols_baja_varianza\" con las variables (columnas) que tienen falta de variabilidad (Repetitividad o NaNs).*\n",
        "\n",
        ">>*Criterio: Columnas con >95% de valores id√©nticos o nulos.*"
      ],
      "metadata": {
        "id": "eI2YnPxC9Lpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_baja_varianza = [\n",
        "    'SOLAR TERMICA',              # 100% \"NO\"\n",
        "    'INFORME_INS_TECNICA_EDIFICI', # 99.83 % NaN\n",
        "    # ... A√±ade aqu√≠ el resto de variables, poniendo al lado el motivo de su inclusi√≥n ...\n",
        "]"
      ],
      "metadata": {
        "id": "hm8p6OVo9aTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-SSXgRi35ps"
      },
      "source": [
        ">>Eliminar columnas no informativas por repetici√≥n de valores o NaNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "258XuvsK35pt"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=cols_baja_varianza, errors='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR1nv1FU35pz"
      },
      "source": [
        "* **S3.T1.2.** Identificar y Eliminar columnas no informativas debido a su nula relaci√≥n con el fen√≥meno de estudio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5ximT8D35p3"
      },
      "outputs": [],
      "source": [
        "# Lista de variables a eliminar por nula relaci√≥n\n",
        "cols_no_relacionadas = [\n",
        "    'NUM_CAS',              # ID administrativo de la Generalitat\n",
        "    'REFERENCIA CADASTRAL', # No influye en la f√≠sica del edificio\n",
        "    # --- A√±ade aqu√≠ el resto de variables detectadas ---\n",
        "]\n",
        "\n",
        "# Ejecuci√≥n de la eliminaci√≥n\n",
        "df = df.drop(columns=cols_no_relacionadas, errors='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **S3.T1.3.** Eliminar observaciones duplicadas. Esto se deber√≠a repetir al final de la limpieza de la BBDD."
      ],
      "metadata": {
        "id": "6iOBTCBkFo36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()  # Eliminar observaciones duplicadas"
      ],
      "metadata": {
        "id": "xXPV4tf4FxsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ta10_kD35p3"
      },
      "source": [
        "---\n",
        "\n",
        "### S3.T2. Tratamiento de datos INCONSISTENTES\n",
        "\n",
        "* **S3.T2.1.** Uniformizar uso de las may√∫sculas/min√∫sculas y corregir errores de escritura en variables categ√≥ricas.\n",
        "* **S3.T2.2.** Errores de formato en direcciones, n√∫meros, ...\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c7B7FzL35p3"
      },
      "source": [
        "* **S3.T2.1.** Uniformizar uso de las may√∫sculas/min√∫sculas y corregir errores de escritura en variables categ√≥ricas.\n",
        "\n",
        ">Las variables categ√≥ricas a menudo presentan \"suciedad\" debido a la entrada manual: mezcla de may√∫sculas, errores ortogr√°ficos o sin√≥nimos. Para limpiar estas variables, seguiremos estas cuatro estrategias:\n",
        "\n",
        ">1. **Normalizaci√≥n de texto:** Convertimos todo a min√∫sculas para que el sistema no trate como categor√≠as distintas palabras que solo var√≠an en su graf√≠a (ej: \"Vivienda\" vs \"vivienda\").\n",
        "\n",
        ">>> `df['COL'] = df['COL'].str.lower()`\n",
        "\n",
        ">2. **Mapeo de sin√≥nimos (Agrupaci√≥n):** Unificamos t√©rminos que significan lo mismo o agrupamos categor√≠as muy similares mediante un diccionario de correcci√≥n.\n",
        "\n",
        ">>> `df['COL'] = df['COL'].replace({'antiguo': 'nuevo'})`\n",
        "\n",
        ">3. **Filtrado de errores:** Si detectamos valores imposibles, s√≠mbolos extra√±os o errores que no pueden corregirse por falta de informaci√≥n, eliminamos esas filas (observaciones).\n",
        "\n",
        ">>> `df = df.drop(df[df['COL'] == 'error'].index, axis=0)`\n",
        "\n",
        ">4. **Tratamiento del ruido:** En variables con much√≠sima dispersi√≥n (como municipios o tipos de uso muy espec√≠ficos), aparecen categor√≠as con poqu√≠simas muestras. Corregirlas manualmente requiere un esfuerzo excesivo para el beneficio que aportan, y estad√≠sticamente pueden \"confundir\" al modelo de IA al no tener suficientes ejemplos para aprender un patr√≥n fiable. Estrategia: Establecemos un umbral m√≠nimo (ej. 400 observaciones). Si una categor√≠a no llega a ese m√≠nimo, eliminamos esas filas para quedarnos con un dataset m√°s robusto y limpio.\n",
        "\n",
        ">>>`counts = df['US_EDIFICI'].value_counts()`\n",
        "\n",
        ">>>`to_remove = counts[counts <= 400].index`\n",
        "\n",
        ">>>`df = df[~df['US_EDIFICI'].isin(to_remove)]`\n",
        "\n",
        ">5. **Evaluar siempre la relaci√≥n esfuerzo/beneficio:** A veces, una variable tiene tantos errores ortogr√°ficos o categor√≠as ca√≥ticas (ej. POBLACIO) que el tiempo necesario para limpiarla no compensa la informaci√≥n que aporta. En estos casos, es m√°s eficiente eliminar la columna completa.\n",
        "\n",
        ">>>`print(df['POBLACIO'].value_counts())`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1aalDaH35p6"
      },
      "outputs": [],
      "source": [
        "# EJEMPLO DE TRATAMIENTO COMPLETO DE UNA VARIABLE: Limpieza de NOM_PROVINCIA\n",
        "\n",
        "print(\"ESTADO INICIAL DE 'NOM_PROVINCIA':\")\n",
        "print(df['NOM_PROVINCIA'].value_counts(dropna=False))\n",
        "\n",
        "# 1. Uniformizar a min√∫sculas\n",
        "df['NOM_PROVINCIA'] = df['NOM_PROVINCIA'].str.lower()\n",
        "\n",
        "# 2. Eliminar observaciones err√≥neas (ejemplo: valor '0')\n",
        "# Identificamos √≠ndices y eliminamos esas filas\n",
        "ind_erroneos = df[df['NOM_PROVINCIA'] == '0'].index\n",
        "df = df.drop(ind_erroneos, axis=0)\n",
        "\n",
        "# 3. Reubicar columna al principio para facilitar la inspecci√≥n visual\n",
        "col_name = \"NOM_PROVINCIA\"\n",
        "df.insert(0, col_name, df.pop(col_name))\n",
        "\n",
        "print(\"\\nESTADO FINAL TRAS LIMPIEZA:\")\n",
        "print(df['NOM_PROVINCIA'].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVRQxk2435p8"
      },
      "outputs": [],
      "source": [
        "# EJEMPLO DE TRATAMIENTO COMPLETO DE UNA VARIABLE: Limpieza de US_EDIFICI\n",
        "\n",
        "print(\"ESTADO INICIAL DE 'US_EDIFICI':\")\n",
        "print(df['US_EDIFICI'].value_counts(dropna=False))\n",
        "\n",
        "df['US_EDIFICI'].value_counts(dropna=False)  # Distribuci√≥n de valores de US_EDIFICI\n",
        "df['US_EDIFICI'] = df['US_EDIFICI'].str.lower()  # Convertir a min√∫sculas\n",
        "# 2. Diccionario de correcciones (Agrupaci√≥n de categor√≠as)\n",
        "correcciones_uso = {\n",
        "    'terciario': 'terciari',\n",
        "    'terciari: locals, oficines...': 'terciari',\n",
        "    'vivienda unifamiliar': 'habitatge unifamiliar',\n",
        "    'habitatge unifamiliar a√Øllat': 'habitatge unifamiliar',\n",
        "    'habitatge unifamiliar adossat': 'habitatge unifamiliar',\n",
        "    'bloque de viviendas': \"bloc d'habitatges plurifamiliar\",\n",
        "    'bloque de viviendas plurifamiliar': \"bloc d'habitatges plurifamiliar\",\n",
        "    \"bloc d'habitatges\": \"bloc d'habitatges plurifamiliar\",\n",
        "    \"habitatge plurifamiliar\": \"bloc d'habitatges plurifamiliar\",\n",
        "    \"vivienda individual en bloque de viviendas\": \"habitatge individual en bloc d'habitatges\",\n",
        "    \"bloque de viviendas\": \"bloc d'habitatges plurifamiliar\"\n",
        "}\n",
        "# Aplicamos el mapeo\n",
        "df['US_EDIFICI'] = df['US_EDIFICI'].replace(correcciones_uso)\n",
        "\n",
        "# 3. Eliminaci√≥n de ruido (Categor√≠as con <= 400 observaciones)\n",
        "counts = df['US_EDIFICI'].value_counts()\n",
        "to_remove = counts[counts <= 400].index\n",
        "df = df[~df['US_EDIFICI'].isin(to_remove)]\n",
        "\n",
        "# 4. Reubicar columna al principio (es una buena pr√°ctica)\n",
        "df.insert(0, 'US_EDIFICI', df.pop('US_EDIFICI'))\n",
        "\n",
        "print(\"\\nESTADO FINAL TRAS LIMPIEZA:\")\n",
        "print(df['US_EDIFICI'].value_counts(dropna=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eyEJSWT35p8"
      },
      "source": [
        ">TAREA: Repite el proceso en una celda de c√≥digo independiente para cada variable categ√≥rica que consideres que se debe limpiar (crea tantas celdas de c√≥digo como necesites)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqmaEDdZ35p8"
      },
      "outputs": [],
      "source": [
        "#Insertar c√≥digo aqu√≠ para la limpieza de la variable 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Insertar c√≥digo aqu√≠ para la limpieza de la variable 2"
      ],
      "metadata": {
        "id": "mBCd5O5dOpGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Insertar c√≥digo aqu√≠ para la limpieza de la variable 3 ..."
      ],
      "metadata": {
        "id": "XWH-XbvhOm1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InR2ItDx35qa"
      },
      "source": [
        "* **S3.T2.2.** Errores de formato en direcciones, n√∫meros, ...\n",
        "\n",
        ">A menudo, los datos num√©ricos vienen \"contaminados\" por formatos regionales (comas en lugar de puntos) o errores de exportaci√≥n que convierten n√∫meros en texto. En esta secci√≥n, aprenderemos a estandarizar estos formatos.\n",
        "\n",
        ">#### Estrategias comunes:\n",
        ">1. **Ceros a la izquierda:** Los c√≥digos postales o IDs deben tener una longitud fija (ej. `08001`). Si se cargan como n√∫meros, el `0` inicial desaparece.\n",
        ">2. **Correcci√≥n de separadores:** En Python, los decimales usan el punto (`.`). Si el dataset usa comas (`,`) para miles o decimales incorrectos, hay que eliminarlas o sustituirlas.\n",
        ">3. **Casteo de tipos (Casting):** Forzar a que una variable sea `float` (n√∫mero con decimales) o `str` (texto) para que las funciones de an√°lisis no den error.\n",
        "\n",
        "*En esta tarea os damos todo el c√≥digo ya realizado. No ten√©is que realizar ni implementar c√≥digo nuevo, simplemente ejecutar el que os proporcionamos.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHkCnuUN35qc"
      },
      "outputs": [],
      "source": [
        "# --- Limpieza de CODI_POSTAL ---\n",
        "\n",
        "print(\"Muestra de C√≥digos Postales iniciales:\")\n",
        "print(df['CODI_POSTAL'].head())\n",
        "\n",
        "# El objetivo es que todos tengan 5 d√≠gitos y sean texto.\n",
        "# 1. Eliminar valores nulos (NaN) ya que no podemos inventar un c√≥digo postal\n",
        "df = df.dropna(subset=['CODI_POSTAL'])\n",
        "\n",
        "# 2. Asegurar formato: De n√∫mero -> a Entero (quita decimal .0) -> a Texto -> Rellenar ceros\n",
        "df['CODI_POSTAL'] = df['CODI_POSTAL'].astype(int).astype(str).str.zfill(5)\n",
        "\n",
        "# 3. Mover al principio\n",
        "df.insert(0, 'CODI_POSTAL', df.pop('CODI_POSTAL'))\n",
        "\n",
        "print(\"Muestra de C√≥digos Postales limpios:\")\n",
        "print(df['CODI_POSTAL'].head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Limpieza de Emissions de CO2 y Energia prim√†ria no renovable ---\n",
        "\n",
        "print(\"Verificaci√≥n de tipos de datos inicial:\")\n",
        "print(df[[\"Emissions de CO2\", \"Energia prim√†ria no renovable\"]].dtypes)\n",
        "\n",
        "# Eliminamos la coma para que Python pueda tratarlos como n√∫meros decimales (float).\n",
        "\n",
        "# Tratamiento de Emissions de CO2\n",
        "df[\"Emissions de CO2\"] = [float(str(i).replace(\",\", \"\")) for i in df[\"Emissions de CO2\"]]\n",
        "\n",
        "# Tratamiento de Energia prim√†ria no renovable\n",
        "df[\"Energia prim√†ria no renovable\"] = [float(str(i).replace(\",\", \"\")) for i in df[\"Energia prim√†ria no renovable\"]]\n",
        "\n",
        "print(\"Verificaci√≥n de tipos de datos final:\")\n",
        "print(df[[\"Emissions de CO2\", \"Energia prim√†ria no renovable\"]].dtypes)\n",
        "\n",
        "# Visualizamos las primeras filas para confirmar que son n√∫meros limpios\n",
        "display(df[[\"Emissions de CO2\", \"Energia prim√†ria no renovable\"]].head())"
      ],
      "metadata": {
        "id": "Xsp2aWJoPyAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_j0Xw2R35qk"
      },
      "outputs": [],
      "source": [
        "# --- Limpieza de Valor finestres y aillaments CTE ---\n",
        "\n",
        "df['VALOR FINESTRES CTE'] = df['VALOR FINESTRES CTE'].astype(str)  # Convertir el tipo de datos de VALOR FINESTRES CTE a str\n",
        "df['VALOR AILLAMENTS CTE'] = df['VALOR AILLAMENTS CTE'].astype(str)  # Convertir el tipo de datos de VALOR AILLAMENTS CTE a str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afhj8MHB35ql"
      },
      "source": [
        "---\n",
        "\n",
        "### S3.T3. Tratamiento de observaciones nulas (missing data)\n",
        "\n",
        "No todos los nulos se deben tratar igual. Dependiendo de cu√°ntos falten y qu√© tipo de variable sea, elegiremos una de estas 5 alternativas:\n",
        "\n",
        "1. **Borrado por densidad:** Si a una fila le faltan casi todos los datos y no tenemos criterio para rellenar los valores, no es √∫til. Borrar observaciones (filas) es \"barato\".\n",
        "2. **Borrado puntual:** Si faltan muy pocos datos en una columna cr√≠tica (ej. `ZONA CLIMATICA`), borramos esas filas, nunca la columna entera.\n",
        "3. **Imputaci√≥n por tendencia central:** Sustituir nulos por la **mediana** (num√©ricas) o la **moda** (categ√≥ricas).\n",
        "4. **Categor√≠a \"Missing\":** Crear una categor√≠a nueva llamada \"DESCONOCIDO\" para no perder la informaci√≥n de las otras columnas.\n",
        "5. **Borrado de columna:** Si la columna aporta poco y est√° casi vac√≠a.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3PMlcAw35ql"
      },
      "source": [
        ">Diagn√≤stico 1: Ver n¬∫ NaNs por columnas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqVePxvb35ql"
      },
      "outputs": [],
      "source": [
        "# 1. Recuento de NaNs por columna\n",
        "\n",
        "# Configuramos pandas para que no ponga l√≠mites al n√∫mero de filas mostradas al imprimir\n",
        "pd.set_option('display.max_rows', 100) # Suficiente para tus 69 columnas\n",
        "\n",
        "print(\"--- Recuento total de NaNs por columna (69 columnas) ---\")\n",
        "# Calculamos los nulos y los mostramos todos\n",
        "nulos_totales = df.isnull().sum().sort_values(ascending=False)\n",
        "print(nulos_totales)\n",
        "\n",
        "# Restablecemos la configuraci√≥n por defecto (opcional, para no saturar futuras celdas)\n",
        "pd.reset_option('display.max_rows')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQXQCOiC35qm"
      },
      "source": [
        ">Diagn√≥stico 2: Ver n¬∫ NaNs por filas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ra4UHuO35qn"
      },
      "outputs": [],
      "source": [
        "# Creamos una serie con el conteo de nulos por cada fila\n",
        "nans_por_fila = df.isnull().sum(axis=1)\n",
        "\n",
        "# Contamos cu√°ntas filas hay con 0 nulos, con 1 nulo, con 2, etc.\n",
        "distribucion_nans = nans_por_fila.value_counts().sort_index()\n",
        "\n",
        "# Visualizaci√≥n\n",
        "distribucion_nans.plot.bar(\n",
        "    figsize=(10, 5),\n",
        "    title=\"Diagn√≥stico 2: ¬øCu√°ntos campos vac√≠os tienen los edificios?\",\n",
        "    xlabel=\"N√∫mero de NaNs detectados en una fila\",\n",
        "    ylabel=\"Cantidad de edificios (registros)\",\n",
        "    color='skyblue',\n",
        "    edgecolor='black'\n",
        ")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">> Alternativa 1: Borrar filas con exceso de NaNs. Por ejemplo, si un edificio tiene m√°s de 6 campos vac√≠os, lo descartamos"
      ],
      "metadata": {
        "id": "WtswGETnVZUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "umbral = 6\n",
        "df = df[df.isnull().sum(axis=1) <= umbral]"
      ],
      "metadata": {
        "id": "DbI_Sez3VZ7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM1YQwbn35qp"
      },
      "source": [
        ">>Alternativa 2: Borrar filas puntuales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9KZLLud35qq"
      },
      "outputs": [],
      "source": [
        "df.drop([5], axis=0)  # Eliminar observaci√≥n con √≠¬≠ndice 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_PWbTBq35qq"
      },
      "source": [
        ">>Alternativa 3: Borrar filas que tengan un NaN en una determinada columna. Apropiado si hay muy pocos NaNs en la columna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6_Jdvtq35qr"
      },
      "outputs": [],
      "source": [
        "df = df.dropna(subset=['ZONA CLIMATICA'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlajGpFU35qr"
      },
      "source": [
        ">>Alternativa 4: Borrar columnas poco informativas que contengan observaciones nulas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9uhzqZ735qs"
      },
      "outputs": [],
      "source": [
        "df = df.drop(df.columns[3], axis=1)  # Eliminar columna 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrsQ1N0635qt"
      },
      "source": [
        ">>Alternativa 5: Asignar un valor a la observaci√≥n nula. Distintos casos seg√∫n variables continuas o categ√≥ricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diDElvcU35qu"
      },
      "outputs": [],
      "source": [
        "med = df['METRES_CADASTRE'].median()  # Calcular la mediana de la variable METRES_CADASTRE\n",
        "df['METRES_CADASTRE'] = df['METRES_CADASTRE'].fillna(med)  # Sustituimos NaNs por la mediana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amEXtUKu35qu"
      },
      "outputs": [],
      "source": [
        "top = df['SISTEMA BIOMASSA'].describe()['top']  # Calcular el valor m√°s frecuente de la variable SISTEMA BIOMASSA\n",
        "df['SISTEMA BIOMASSA'] = df['SISTEMA BIOMASSA'].fillna(top)  # Sustituimos NaNs por el campo m√É¬°s com√É¬∫n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Qrd9bT35qv"
      },
      "outputs": [],
      "source": [
        "df['XARXA DISTRICTE'] = df['XARXA DISTRICTE'].fillna('MISSING')  # Sustituimos NaNs una categor√≠¬≠a nueva"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2oZlaYB35qw"
      },
      "source": [
        ">TAREA: Trata las observaciones NaNs de tu base de datos con adoptando la alternativa m√°s adiente en cada caso. Justifica tu decisi√≥n con un comentario al lado del c√≥digo. El objetivo es terminar sin ning√∫n NaN en tu BBDD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUwzJgpJ35qw"
      },
      "source": [
        "EJEMPLO Limpieza de ZONA CLIMATICA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbUaxc6C35qx"
      },
      "outputs": [],
      "source": [
        "# EJEMPLO DE TRATAMIENTO COMPLETO DE UNA VARIABLE: Zona clim√°tica\n",
        "# 1. Diagn√≥stico: ¬øCu√°ntos nulos tenemos realmente?\n",
        "num_missing = df[\"ZONA CLIMATICA\"].isnull().sum()\n",
        "print(f\"Valores nulos iniciales en ZONA CLIMATICA: {num_missing}\")\n",
        "\n",
        "# 2. Decisi√≥n y Ejecuci√≥n:\n",
        "# Como solo hay 46 nulos sobre miles de registros, la p√©rdida es despreciable (<1%).\n",
        "# Optamos por eliminar las filas (Alternativa 3).\n",
        "df = df[df['ZONA CLIMATICA'].notna()]\n",
        "\n",
        "# 3. Organizaci√≥n:\n",
        "# Movemos la columna al principio para facilitar la inspecci√≥n visual\n",
        "col_name = \"ZONA CLIMATICA\"\n",
        "first_col = df.pop(col_name)\n",
        "df.insert(0, col_name, first_col)\n",
        "\n",
        "num_missing = df[\"ZONA CLIMATICA\"].isnull().sum()\n",
        "print(f\"Valores nulos finales en ZONA CLIMATICA: {num_missing}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Introduce aqu√≠ el c√≥digo para la limpieza de otra variable (utiliza una celda de c√≥digo por variable)"
      ],
      "metadata": {
        "id": "pFYso6Rtb5RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bECQsmq-35q1"
      },
      "source": [
        "---\n",
        "\n",
        "### S3.T4. Tratamiento de Outliers en Variables Continuas\n",
        "\n",
        "No todos los nulos se deben tratar igual. Dependiendo de cu√°ntos falten y qu√© tipo de variable sea, elegiremos una de estas 5 alternativas:\n",
        "\n",
        "Un **outlier** en una variable continua es un valor que se aleja dr√°sticamente del comportamiento general. En nuestro contexto (edificios), suele indicar:\n",
        "* **Errores de entrada:** Un edificio de 100,000 $m^2$ que en realidad ten√≠a 100.\n",
        "* **Casos at√≠picos:** Edificios singulares que no representan la norma y que pueden sesgar las predicciones de la IA.\n",
        "\n",
        "En ambos casos, hay que eliminar estas observaciones de nuestra base de datos.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MAadRav35q4"
      },
      "source": [
        "Paso 1: Diagn√≥stico Visual y Estad√≠stico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHrybjZN35q5"
      },
      "outputs": [],
      "source": [
        "# 1. Diagn√≥stico estad√≠stico y visual\n",
        "print(df['METRES_CADASTRE'].describe())\n",
        "\n",
        "# Visualizamos la densidad para detectar \"colas\" largas en el gr√°fico\n",
        "sns.kdeplot(data=df['METRES_CADASTRE'])\n",
        "plt.title(\"Distribuci√≥n de Metros Cuadrados\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIk5SGJO35q6"
      },
      "source": [
        "Paso 2: Control de filas a eliminar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDuPyT8935q8"
      },
      "outputs": [],
      "source": [
        "# 1. Definir l√≠mites basados en el diagn√≥stico anterior\n",
        "limite_inferior = 5\n",
        "limite_superior = 50000\n",
        "\n",
        "# 2. Identificar y Contar\n",
        "ind_out = df[(df['METRES_CADASTRE'] < limite_inferior) | (df['METRES_CADASTRE'] > limite_superior)].index\n",
        "\n",
        "print(f\"Registros que se eliminar√°n: {len(ind_out)}\")\n",
        "print(f\"Porcentaje de p√©rdida: {(len(ind_out) / len(df)) * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 3: Eliminaci√≥n y validaci√≥n"
      ],
      "metadata": {
        "id": "RiSXHin_bMDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. EJECUCI√ìN (Solo si el porcentaje es razonable)\n",
        "if len(ind_out) > 0:\n",
        "    df = df.drop(ind_out, axis=0)\n",
        "    # Reubicamos la columna para ver el resultado\n",
        "    df.insert(0, 'METRES_CADASTRE', df.pop('METRES_CADASTRE'))\n",
        "    print(f\"\\n Eliminaci√≥n completada. Nuevo tama√±o: {df.shape[0]} filas.\")\n",
        "else:\n",
        "    print(\"\\n No se han eliminado registros.\")"
      ],
      "metadata": {
        "id": "AbugSvEGbGCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT-Ug_ib35q-"
      },
      "source": [
        "TAREA: Elimina los outliers de tu base de datos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Introduce aqu√≠ el c√≥digo para la limpieza de otra variable (utiliza una celda de c√≥digo por variable)"
      ],
      "metadata": {
        "id": "RThR1YjtcJK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4GgyxqM35q_"
      },
      "source": [
        "Eliminar observaciones duplicadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rONJCqct35q_"
      },
      "outputs": [],
      "source": [
        "n_antes_dupl = len(df)\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Registros duplicados eliminados: {n_antes_dupl - len(df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqUh6M3735rA"
      },
      "source": [
        "Guardar BBDD limpia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFQYpSox35rB"
      },
      "outputs": [],
      "source": [
        "# Usamos la misma carpeta donde cargamos la BBDD_ST2\n",
        "ruta_salida = '/content/drive/MyDrive/Sostenibilidad/BBDD_ST3.csv'\n",
        "df.to_csv(ruta_salida, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpSfc0PP35rB"
      },
      "source": [
        "# üèÅ TAREAS FINALES: Wrap-up de la Sesi√≥n de Trabajo 3\n",
        "\n",
        "**Descripci√≥n:** Una vez finalizado el proceso de depuraci√≥n, es necesario auditar la calidad de la base de datos resultante. Contesta a las siguientes preguntas comparando el estado inicial (**BBDD_ST2**) y el estado final tras la limpieza (**BBDD_ST3**).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Auditor√≠a de Dimensiones\n",
        "Realiza un balance del volumen de datos tras aplicar los filtros de nulos, duplicados y outliers.\n",
        "\n",
        "* **N√∫mero de filas:**\n",
        "    * *Antes (ST2):* `______`\n",
        "    * *Despu√©s (ST3):* `______`\n",
        "* **N√∫mero de columnas:**\n",
        "    * *Antes (ST2):* `______`\n",
        "    * *Despu√©s (ST3):* `______`\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Definici√≥n del Modelo del proceso de certificaci√≥n\n",
        "Identifica las variables que ser√°n el motor de tu modelo en la pr√≥xima sesi√≥n.\n",
        "\n",
        "* **Variables INPUTS (Entradas):** Escribe el nombre de las columnas que usar√°s como posibles INPUTS (Entradas) en el proceso de certificaci√≥n.\n",
        "    * *Respuesta:*\n",
        "* **Variables OUTPUTS (Salidas):** Escribe el nombre de las columnas que usar√°s como posibles OUTPUTS (Salidas) del proceso de certificaci√≥n.\n",
        "    * *Respuesta:*\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Impacto de la limpieza por Variable\n",
        "\n",
        "A continuaci√≥n, detalla los cambios espec√≠ficos en todas las variables no eliminadas.\n",
        "\n",
        "#### **A. Variables Categ√≥ricas (Unificaci√≥n y Ruido)**\n",
        "| Variable | N¬∫ Categor√≠as Inicial (ST2) | N¬∫ Categor√≠as Final (ST3) | Comentario (ej: ¬øQu√© agrupaste?) |\n",
        "| :--- | :---: | :---: | :--- |\n",
        "| `US_EDIFICI` | | | |\n",
        "| `NOM_PROVINCIA` | | | |\n",
        "| `ZONA CLIMATICA` | | | |\n",
        "\n",
        "#### **B. Variables Continuas (Eliminaci√≥n de Outliers)**\n",
        "| Variable | Valor M√≠n / M√°x (ST2) | Valor M√≠n / M√°x (ST3) | ¬øPor qu√© elegiste esos l√≠mites? |\n",
        "| :--- | :---: | :---: | :--- |\n",
        "| `METRES_CADASTRE` | | | |\n",
        "| `compacitat` | | | |\n",
        "| `Emissions de CO2` | | | |\n",
        "| `Energia prim√†ria...`| | | |"
      ],
      "metadata": {
        "id": "DZq-DtUjeG0v"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}